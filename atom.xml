<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>水冼雪</title>
  <subtitle>抬头看天，低头赶路</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://luxialan.com/"/>
  <updated>2017-02-16T06:38:20.638Z</updated>
  <id>http://luxialan.com/</id>
  
  <author>
    <name>luxialan</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>【概率论与数理统计】 读书笔记</title>
    <link href="http://luxialan.com/2017/02/16/%E3%80%90%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E3%80%91-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <id>http://luxialan.com/2017/02/16/【概率论与数理统计】-读书笔记/</id>
    <published>2017-02-16T06:34:39.000Z</published>
    <updated>2017-02-16T06:38:20.638Z</updated>
    
    <content type="html"><![CDATA[<p>概率论与数理统计基础知识总结<br><a id="more"></a></p>
<ul>
<li>第一章 随机事件与概率</li>
<li>第二章 随机变量及其分布</li>
<li>第三章 多维随机变量及其分布</li>
<li>第四章 大数定律与中心极限定理</li>
<li>第五章 统计量及其分布</li>
<li>第六章 参数估计</li>
<li>第七章 假设检验</li>
<li>第八章 方差分析与回归分析</li>
</ul>
<h3 id="第一章-随机事件与概率"><a href="#第一章-随机事件与概率" class="headerlink" title="第一章 随机事件与概率"></a>第一章 随机事件与概率</h3><h4 id="1-1-随机事件及其运算"><a href="#1-1-随机事件及其运算" class="headerlink" title="1.1 随机事件及其运算"></a>1.1 随机事件及其运算</h4><p>概率论与数理统计研究的对象是随机现象. 概率论是研究随机现象的模型（即概率分布），数理统计是研究随机现象的数据收集与处理。</p>
<ul>
<li>随机现象： 在一定的条件下，并不总是出现相同结果的现象称为随机现象</li>
<li>样本空间：随机现象的一切可能基本结果组成的集合称为样本空间</li>
<li>随机事件：随机现象的某些样本点组成的集合称为随机事件</li>
<li>随机变量：用来表示随机现象结果的变量称为随机变量</li>
<li>事件间的关系：包含，相等，互不相容</li>
<li>事件的运算：并、交、差、对立</li>
<li>事件的运算性质：交换律、结合律、分配律、对偶律</li>
<li>事件域</li>
</ul>
<h4 id="1-2-概率的定义及其确定方法"><a href="#1-2-概率的定义及其确定方法" class="headerlink" title="1.2 概率的定义及其确定方法"></a>1.2 概率的定义及其确定方法</h4><h5 id="概率的公理化定义"><a href="#概率的公理化定义" class="headerlink" title="概率的公理化定义"></a>概率的公理化定义</h5><ul>
<li>非负性公理</li>
<li>正则性公理</li>
<li>可列可加性公理<h5 id="排列与组合性质"><a href="#排列与组合性质" class="headerlink" title="排列与组合性质"></a>排列与组合性质</h5></li>
<li>乘法原理</li>
<li>加法原理<h5 id="排列与组合公式"><a href="#排列与组合公式" class="headerlink" title="排列与组合公式"></a>排列与组合公式</h5></li>
<li>排列 P(r,n) </li>
<li>重复排列 n^r</li>
<li>组合 C(r,n) </li>
<li>重复组合 C(r, n+r-1)<h5 id="确定概率的两种方法"><a href="#确定概率的两种方法" class="headerlink" title="确定概率的两种方法"></a>确定概率的两种方法</h5></li>
<li>确定概率的频率方法</li>
<li>确定概率的古典方法</li>
</ul>
<h4 id="1-3概率的性质"><a href="#1-3概率的性质" class="headerlink" title="1.3概率的性质"></a>1.3概率的性质</h4><ul>
<li>概率的可加性</li>
<li>概率的单调性</li>
<li>概率的加法公式</li>
<li>概率的连续性</li>
</ul>
<h4 id="1-4条件概率"><a href="#1-4条件概率" class="headerlink" title="1.4条件概率"></a>1.4条件概率</h4><ul>
<li>乘法公式</li>
<li>全概率公式</li>
<li>贝叶斯公式</li>
</ul>
<h4 id="1-5独立性"><a href="#1-5独立性" class="headerlink" title="1.5独立性"></a>1.5独立性</h4><p>一个事件的发生不影响另一个事件的发生</p>
<h3 id="第二章-随机变量及其分布"><a href="#第二章-随机变量及其分布" class="headerlink" title="第二章 随机变量及其分布"></a>第二章 随机变量及其分布</h3><h4 id="2-1-随机变量及其分布"><a href="#2-1-随机变量及其分布" class="headerlink" title="2.1 随机变量及其分布"></a>2.1 随机变量及其分布</h4><h5 id="随机变量的分布函数"><a href="#随机变量的分布函数" class="headerlink" title="随机变量的分布函数"></a>随机变量的分布函数</h5><ul>
<li>单调性</li>
<li>有界性</li>
<li>右连续性</li>
</ul>
<h5 id="离散随机变量的概率分布列"><a href="#离散随机变量的概率分布列" class="headerlink" title="离散随机变量的概率分布列"></a>离散随机变量的概率分布列</h5><p>分布列的基本性质</p>
<ul>
<li>非负性</li>
<li>正则性</li>
</ul>
<h4 id="2-2-随机变量的数学期望"><a href="#2-2-随机变量的数学期望" class="headerlink" title="2.2 随机变量的数学期望"></a>2.2 随机变量的数学期望</h4><p>数学期望的性质</p>
<h4 id="2-3-随机变量的方差与标准差"><a href="#2-3-随机变量的方差与标准差" class="headerlink" title="2.3 随机变量的方差与标准差"></a>2.3 随机变量的方差与标准差</h4><ul>
<li>切比雪夫不等式 </li>
</ul>
<h4 id="2-4常用离散分布"><a href="#2-4常用离散分布" class="headerlink" title="2.4常用离散分布"></a>2.4常用离散分布</h4><ul>
<li>二项分布</li>
<li>二点分布</li>
<li>泊松分布</li>
<li>超几何分布</li>
<li>几何分布</li>
</ul>
<h4 id="2-5常用连续分布"><a href="#2-5常用连续分布" class="headerlink" title="2.5常用连续分布"></a>2.5常用连续分布</h4><ul>
<li>正态分布</li>
<li>均匀分布</li>
<li>指数分布</li>
<li>伽马分布</li>
<li>贝塔分布</li>
</ul>
<h4 id="2-6-随机变量函数的分布"><a href="#2-6-随机变量函数的分布" class="headerlink" title="2.6 随机变量函数的分布"></a>2.6 随机变量函数的分布</h4><h4 id="2-7-分布的其他特征数"><a href="#2-7-分布的其他特征数" class="headerlink" title="2.7 分布的其他特征数"></a>2.7 分布的其他特征数</h4><ul>
<li>k阶矩</li>
<li>k阶原点矩</li>
<li>k阶中心矩</li>
<li>变异系数</li>
<li>分位数</li>
<li>中位数</li>
<li>偏度系数</li>
<li>峰度系数</li>
</ul>
<h3 id="第三章-多维随机变量及其分布"><a href="#第三章-多维随机变量及其分布" class="headerlink" title="第三章 多维随机变量及其分布"></a>第三章 多维随机变量及其分布</h3><h4 id="3-1-多维随机变量及其联合分布"><a href="#3-1-多维随机变量及其联合分布" class="headerlink" title="3.1 多维随机变量及其联合分布"></a>3.1 多维随机变量及其联合分布</h4><h5 id="多维随机变量"><a href="#多维随机变量" class="headerlink" title="多维随机变量"></a>多维随机变量</h5><ul>
<li>联合分布函数</li>
<li>联合分布列</li>
<li>联合密度函数<h5 id="多项分布"><a href="#多项分布" class="headerlink" title="多项分布"></a>多项分布</h5></li>
<li>多维超几何分布</li>
<li>多维均匀分布</li>
<li>二元正态分布</li>
</ul>
<h4 id="3-2-边际分布与随机变量的独立性"><a href="#3-2-边际分布与随机变量的独立性" class="headerlink" title="3.2 边际分布与随机变量的独立性"></a>3.2 边际分布与随机变量的独立性</h4><h5 id="多维随机变量函数的分布"><a href="#多维随机变量函数的分布" class="headerlink" title="多维随机变量函数的分布"></a>多维随机变量函数的分布</h5><h5 id="多维随机变量的特征数"><a href="#多维随机变量的特征数" class="headerlink" title="多维随机变量的特征数"></a>多维随机变量的特征数</h5><h5 id="条件分布与条件期望"><a href="#条件分布与条件期望" class="headerlink" title="条件分布与条件期望"></a>条件分布与条件期望</h5><h3 id="第四章-大数定律与中心极限定理"><a href="#第四章-大数定律与中心极限定理" class="headerlink" title="第四章 大数定律与中心极限定理"></a>第四章 大数定律与中心极限定理</h3><h4 id="4-1-随机变量序列的两种收敛性"><a href="#4-1-随机变量序列的两种收敛性" class="headerlink" title="4.1 随机变量序列的两种收敛性"></a>4.1 随机变量序列的两种收敛性</h4><h3 id="第五章-统计量及其分布"><a href="#第五章-统计量及其分布" class="headerlink" title="第五章 统计量及其分布"></a>第五章 统计量及其分布</h3><h4 id="5-1-总体与样本"><a href="#5-1-总体与样本" class="headerlink" title="5.1 总体与样本"></a>5.1 总体与样本</h4><h3 id="第六章-参数估计"><a href="#第六章-参数估计" class="headerlink" title="第六章 参数估计"></a>第六章 参数估计</h3><h4 id="6-1-点估计的概念与无偏性"><a href="#6-1-点估计的概念与无偏性" class="headerlink" title="6.1 点估计的概念与无偏性"></a>6.1 点估计的概念与无偏性</h4><h4 id="6-2-矩估计及相合性"><a href="#6-2-矩估计及相合性" class="headerlink" title="6.2 矩估计及相合性"></a>6.2 矩估计及相合性</h4><h4 id="6-3-最大似然估计与EM算法"><a href="#6-3-最大似然估计与EM算法" class="headerlink" title="6.3 最大似然估计与EM算法"></a>6.3 最大似然估计与EM算法</h4><h4 id="6-4-最小方差无偏估计"><a href="#6-4-最小方差无偏估计" class="headerlink" title="6.4 最小方差无偏估计"></a>6.4 最小方差无偏估计</h4><h4 id="6-5-贝叶斯估计"><a href="#6-5-贝叶斯估计" class="headerlink" title="6.5 贝叶斯估计"></a>6.5 贝叶斯估计</h4><h4 id="6-6-区间估计"><a href="#6-6-区间估计" class="headerlink" title="6.6 区间估计"></a>6.6 区间估计</h4><h3 id="第七章-假设检验"><a href="#第七章-假设检验" class="headerlink" title="第七章 假设检验"></a>第七章 假设检验</h3><h4 id="7-1-假设检验的基本思想和概念"><a href="#7-1-假设检验的基本思想和概念" class="headerlink" title="7.1 假设检验的基本思想和概念"></a>7.1 假设检验的基本思想和概念</h4><h4 id="7-2-正态总体参数假设检验"><a href="#7-2-正态总体参数假设检验" class="headerlink" title="7.2 正态总体参数假设检验"></a>7.2 正态总体参数假设检验</h4><h4 id="7-3-其他分布参数的假设检验"><a href="#7-3-其他分布参数的假设检验" class="headerlink" title="7.3 其他分布参数的假设检验"></a>7.3 其他分布参数的假设检验</h4><h4 id="7-4-似然比检验与分布拟合检验"><a href="#7-4-似然比检验与分布拟合检验" class="headerlink" title="7.4 似然比检验与分布拟合检验"></a>7.4 似然比检验与分布拟合检验</h4><h4 id="7-5-正态性检验"><a href="#7-5-正态性检验" class="headerlink" title="7.5 正态性检验"></a>7.5 正态性检验</h4><h4 id="7-6-非参数检验"><a href="#7-6-非参数检验" class="headerlink" title="7.6 非参数检验"></a>7.6 非参数检验</h4><h3 id="第八章-方差分析与回归分析"><a href="#第八章-方差分析与回归分析" class="headerlink" title="第八章 方差分析与回归分析"></a>第八章 方差分析与回归分析</h3><h4 id="8-1-方差分析"><a href="#8-1-方差分析" class="headerlink" title="8.1 方差分析"></a>8.1 方差分析</h4><h4 id="8-2-多重比较"><a href="#8-2-多重比较" class="headerlink" title="8.2 多重比较"></a>8.2 多重比较</h4><h4 id="8-3-方差齐性检验"><a href="#8-3-方差齐性检验" class="headerlink" title="8.3 方差齐性检验"></a>8.3 方差齐性检验</h4><h4 id="8-4-一元线性回归"><a href="#8-4-一元线性回归" class="headerlink" title="8.4 一元线性回归"></a>8.4 一元线性回归</h4><h4 id="8-5-一元非线性回归"><a href="#8-5-一元非线性回归" class="headerlink" title="8.5 一元非线性回归"></a>8.5 一元非线性回归</h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;概率论与数理统计基础知识总结&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="知识储备" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/"/>
    
    
      <category term="Book" scheme="http://luxialan.com/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>理财基础指南</title>
    <link href="http://luxialan.com/2017/02/15/%E7%90%86%E8%B4%A2%E5%9F%BA%E7%A1%80%E6%8C%87%E5%8D%97/"/>
    <id>http://luxialan.com/2017/02/15/理财基础指南/</id>
    <published>2017-02-15T08:37:54.000Z</published>
    <updated>2017-02-16T06:47:31.072Z</updated>
    
    <content type="html"><![CDATA[<p>你不理财，财不理你<br><a id="more"></a><br>投资渠道</p>
<ul>
<li>基金定投</li>
<li>银行储蓄</li>
<li>余额宝类产品</li>
<li>P2P网贷</li>
</ul>
<h3 id="基金："><a href="#基金：" class="headerlink" title="基金："></a>基金：</h3><h4 id="基金分红"><a href="#基金分红" class="headerlink" title="基金分红:"></a>基金分红:</h4><p>现金分红、红利再投资。</p>
<h4 id="货币基金："><a href="#货币基金：" class="headerlink" title="货币基金："></a>货币基金：</h4><p>基金资产全部投资于短期货币市场工具，比如银行大额存单等无风险或者低风险的资产。</p>
<h4 id="债券基金："><a href="#债券基金：" class="headerlink" title="债券基金："></a>债券基金：</h4><p>基金资产80%以上投资于各类债券，比如企业债券、金融债券等。债券型基金又分为纯债型基金和偏债型基金(或者称为二级债基)。<br>纯债基金:资产=债券+银行存款，风险收益低，一般在5%-10%左右；<br>二级债基:资产=债券+银行存款+不超过20%的股票。风险适中，收益比纯债基好，一般在10%-20%之间。</p>
<h4 id="股票型基金："><a href="#股票型基金：" class="headerlink" title="股票型基金："></a>股票型基金：</h4><p>资产中80%以上投资于股票。风险大，收益高，15%以上的年化收益问题不大。</p>
<h4 id="混合型基金："><a href="#混合型基金：" class="headerlink" title="混合型基金："></a>混合型基金：</h4><p>资产=股票+债券+货币市场工具。股票和债券投资比例灵活。收益在股票基金和债券基金之间。</p>
<h4 id="指数型基金："><a href="#指数型基金：" class="headerlink" title="指数型基金："></a>指数型基金：</h4><p>仅投资标的指数的成份股，对指数进行复制。<br>指数基金的目的不是为了获得超越市场的收益，而是让这个投资组合的波动与该指数一致，取得与指数大致相同的收益率。<br>四大常见指数</p>
<ul>
<li>沪深300：这是个跨市场的指数，是从上海和深圳证券市场中选取300只规模大、流动性好的300只股票作为样本；覆盖了沪深市场60%左右的市值，具有良好的市场代表性。</li>
<li>中证500：扣除沪深300指数样本、按日均总市值高低排名选取前500名股票作为样本，综合反映沪深证券市场内小市值公司的整体状况；是一只综合体现沪深两市小市值企业的指数，是期望分享高成长收益投资者的最佳选择。</li>
<li>上证50: 挑选上海证券市场规模大、流动性好的最具代表性的50只股票组成样本股，综合反映上海证券市场最具市场影响力的一批龙头企业的整体状况；是优质蓝筹股的突触代表。</li>
<li>中证100：从沪深300指数样本股中挑选规模最大的100只股票组成样本股，以综合反映沪深证券市场中最具市场影响力的一批大市值公司的整体状况。</li>
</ul>
<h4 id="基金价值的衡量：基金的净值代表一份基金值多少钱。但是对于投资者而言，应该关心基金未来的净值。"><a href="#基金价值的衡量：基金的净值代表一份基金值多少钱。但是对于投资者而言，应该关心基金未来的净值。" class="headerlink" title="基金价值的衡量：基金的净值代表一份基金值多少钱。但是对于投资者而言，应该关心基金未来的净值。"></a>基金价值的衡量：基金的净值代表一份基金值多少钱。但是对于投资者而言，应该关心基金未来的净值。</h4><h2 id="个人总结"><a href="#个人总结" class="headerlink" title="个人总结"></a>个人总结</h2><p>理财重要的核心</p>
<ul>
<li>复利，滴水石穿，积少成多</li>
<li>预期，比现在更重要的是未来</li>
<li>价值，价格会波动，但是最终会回归价值</li>
<li>投资与保值，资产不是一个固定的概念，而是一个流动的概念，即使不是为赚钱投资，为了资产不贬值，也需要对资产进行不同形式的配置。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;你不理财，财不理你&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="经济金融" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%BB%8F%E6%B5%8E%E9%87%91%E8%9E%8D/"/>
    
    
      <category term="Economy/Finance" scheme="http://luxialan.com/tags/Economy-Finance/"/>
    
  </entry>
  
  <entry>
    <title>【深度学习】 读书笔记 伍 机器学习基础</title>
    <link href="http://luxialan.com/2017/02/14/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E4%BC%8D-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    <id>http://luxialan.com/2017/02/14/【深度学习】-读书笔记-伍-机器学习基础/</id>
    <published>2017-02-14T06:38:12.000Z</published>
    <updated>2017-02-15T12:54:39.778Z</updated>
    
    <content type="html"><![CDATA[<p>机器学习本质上属于应用统计学，更多关注于如何用计算机统计地估计复杂函数，不太关注这些函数的置信区间。<br><a id="more"></a></p>
<ul>
<li>1.学习算法</li>
<li>2.容量、过拟合和欠拟合</li>
<li>3.超参数和验证集</li>
<li>4.估计、偏差和方差</li>
<li>5.最大似然估计</li>
<li>6.贝叶斯统计</li>
<li>7.监督学习方法</li>
<li>8.无监督学习方法</li>
<li>9.随机梯度下降</li>
<li>10.构建机器学习算法</li>
<li>11.推动机深度学习的挑战</li>
</ul>
<h2 id="学习算法"><a href="#学习算法" class="headerlink" title="学习算法"></a>学习算法</h2><p>对于某类任务$T$和性能度量$P$,一个计算机程序被认为可以从经验$E$中学习是指，通过经验E改进后，它在任务$T$上由性能度量$P$衡量的性能有所提升。</p>
<h3 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h3><ul>
<li>分类</li>
<li>输入缺失分类</li>
<li>回归</li>
<li>转录</li>
<li>机器翻译</li>
<li>结构化输出</li>
<li>异常检测</li>
<li>合成和采样</li>
<li>缺失值填补</li>
<li>去噪</li>
<li>密度估计或概率分布律函数估计</li>
</ul>
<h3 id="性能度量，-P"><a href="#性能度量，-P" class="headerlink" title="性能度量，$P$"></a>性能度量，$P$</h3><ul>
<li>准确率</li>
<li>错误率</li>
<li>测试集</li>
</ul>
<h3 id="经验"><a href="#经验" class="headerlink" title="经验"></a>经验</h3><ul>
<li>无监督学习算法</li>
<li>有监督学习算法</li>
</ul>
<h3 id="实例-线性回归"><a href="#实例-线性回归" class="headerlink" title="实例:线性回归"></a>实例:线性回归</h3><p>目标是建立一个系统，将向量$x\in\mathbb{R}^n$作为输入，预测标量$y\in \mathbb{R}$作为输出。线性回归的输出是其输入的线性函数。</p>
<h2 id="容量，过拟合和欠拟合"><a href="#容量，过拟合和欠拟合" class="headerlink" title="容量，过拟合和欠拟合"></a>容量，过拟合和欠拟合</h2><h3 id="泛化"><a href="#泛化" class="headerlink" title="泛化"></a>泛化</h3><p>在未观测到的输入上表现良好的能力被称为泛化(generalization).</p>
<h3 id="性能的测量"><a href="#性能的测量" class="headerlink" title="性能的测量"></a>性能的测量</h3><p>训练误差，泛化误差\测试误差</p>
<h3 id="独立同分布假设"><a href="#独立同分布假设" class="headerlink" title="独立同分布假设"></a>独立同分布假设</h3><p>该假设是说，每个数据集中的样本都是彼此相互独立的，并且训练集和测试集是同分布的，其上数据采样自相同的分布。这个假设使我们能够在单个样本上用概率分布描述数据生成过程。然后相同的分布可以用来生成每一个训练样本和每一个测试样本。<br>测试误差期望会大于或等于训练误差期望。以下是决定机器学习算法效果是否好的因素：</p>
<ul>
<li>降低训练误差</li>
<li>缩小训练误差和测试误差的差距<br>这两个因素对应机器学习的两个主要挑战。</li>
<li>欠拟合。欠拟合发生在模型不能再训练集上获得足够的误差。</li>
<li>过拟合。过拟合发生在训练误差和测试误差之间的差距过大。</li>
</ul>
<h3 id="容量"><a href="#容量" class="headerlink" title="容量"></a>容量</h3><p>模型的容量是指其拟合各种函数的能力。容量低的模型可能很难拟合训练集。容量高的模型可能会过拟合，因为记住了不适用于测试集的训练集性质。</p>
<h3 id="控制容量-一种控制训练算法容量的方法是选择假设空间，即能够选为解决方案的学习算法函数集。例如，线性回归函数将关于其输入的所有线性函数作为假设空间。广义线性回归的假设空间包括多项式函数，而非仅有线性函数。"><a href="#控制容量-一种控制训练算法容量的方法是选择假设空间，即能够选为解决方案的学习算法函数集。例如，线性回归函数将关于其输入的所有线性函数作为假设空间。广义线性回归的假设空间包括多项式函数，而非仅有线性函数。" class="headerlink" title="控制容量:一种控制训练算法容量的方法是选择假设空间，即能够选为解决方案的学习算法函数集。例如，线性回归函数将关于其输入的所有线性函数作为假设空间。广义线性回归的假设空间包括多项式函数，而非仅有线性函数。"></a>控制容量:一种控制训练算法容量的方法是选择假设空间，即能够选为解决方案的学习算法函数集。例如，线性回归函数将关于其输入的所有线性函数作为假设空间。广义线性回归的假设空间包括多项式函数，而非仅有线性函数。</h3><h3 id="奥卡姆剃刀-Occam’s-razor"><a href="#奥卡姆剃刀-Occam’s-razor" class="headerlink" title="奥卡姆剃刀(Occam’s razor)"></a>奥卡姆剃刀(Occam’s razor)</h3><p>统计学习理论提供了量化模型容量的不同方法。在这些中，最有名的是${Vapnik-Chervonenkis}$维度。VC维定义为该分类器能够分类的训练样本的最大数目。</p>
<h3 id="没有免费午餐定理。"><a href="#没有免费午餐定理。" class="headerlink" title="没有免费午餐定理。"></a>没有免费午餐定理。</h3><p>在所有可能的数据生成分布上平均，每一个分类算法在未事先观测的点上都有相同的错误率。换言之，在某种意义上，没有一个机器学习算法总是比其他的要好。<br>幸运的是，这些结论仅在我们考虑所有可能的数据生成分布时才成立。对遇到的概率分布进行假设的话，那么我们可以设计在这些分布上效果良好的学习算法。这意味着机器学习研究的目标不是找一个通用学习算法或是绝对最好的学习算法。我们的目标是理解什么样的分布和人工智能获取经验的“真实世界”相关，什么样的学习算法在我们关注的数据生成分布上效果最好。</p>
<h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><p>没有免费午餐定理暗示我们必须在特定任务上设计性能良好的机器学习算法。当这些偏好和我们希望算法解决的学习问题相吻合时，性能会更好。<br>算法的效果不仅受影响于假设空间的函数数量，也取决于这些函数的具体形式。可以通过控制允许采样的函数种类的方式，也可以通过控制这些函数的数量的方式。</p>
<h2 id="超参数和验证集"><a href="#超参数和验证集" class="headerlink" title="超参数和验证集"></a>超参数和验证集</h2><h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><p>在原始数据上随机采样或分离出的不同数据集上重复训练和测试的想法。最常见的是$k$-折交叉验证过程：</p>
<ul>
<li>将数据集分成k个不重合的子集。测试误差可以估计为$k$次计算后的平均测试误差。在第$i$次测试时，数据的第$i$个子集用于测试集，其他的数据用于训练集。</li>
</ul>
<h2 id="估计，偏差和方差"><a href="#估计，偏差和方差" class="headerlink" title="估计，偏差和方差"></a>估计，偏差和方差</h2><p>统计领域为我们提供了很多工具用于实现机器学习目标，不仅可以解决训练集上的任务，还可以泛化。基本的概念，例如参数估计，偏差和方差，对于形式化刻画泛化，欠拟合和过拟合都非常有帮助。</p>
<h3 id="点估计"><a href="#点估计" class="headerlink" title="点估计"></a>点估计</h3><p>点估计试图为一些感兴趣的量提供单个“最优”预测。一般地，感兴趣的量可以是单个参数，或是某些参数模型中的一个向量参数。<br>为了区分参数估计和真实值，我们习惯表示参数$\theta$的点估计为$\hat{\theta}$<br>让${x^{1},…,x^{m}}$是m个独立同分布的数据点。点估计或统计量是这些数据的任意函数：<br>$$\hat{\theta_m}=g(x^{(1)},…,x^(m))$$<br>一个好的估计量的输出会接近生成训练数据的真实参数$/theta$。<br>点估计也可以指输入和目标变量之间关系的估计。我们将这类点估计称为函数估计。</p>
<h3 id="偏差"><a href="#偏差" class="headerlink" title="偏差"></a>偏差</h3><p>估计的偏差：$bias(\hat{\theta_m})=\mathbb{E}(\hat{\theta_m})-\theta$<br>无偏：$\mathbb{E}(\hat{\theta<em>m})=\theta$<br>渐近无偏：$lim</em>{m-\mapsto\infty}\mathbb{E}(\hat{\theta_m})=\theta$</p>
<h3 id="方差和标准误差"><a href="#方差和标准误差" class="headerlink" title="方差和标准误差"></a>方差和标准误差</h3><p>数据样本函数的变化程度。计算估计量的期望来决定他的偏差。<br>估计量的方差</p>
<h2 id="监督学习算法"><a href="#监督学习算法" class="headerlink" title="监督学习算法"></a>监督学习算法</h2><h3 id="概率监督学习"><a href="#概率监督学习" class="headerlink" title="概率监督学习"></a>概率监督学习</h3><p>本书的大部分监督学习算法都是基于估计概率分布$p(y|x)$。我们可以使用最大似然估计找到对于有参分布族$p(y|x,\theta)$最好的参数向量$\theta$<br>$$p(y|x,\theta)=N(y;\theta^{T}x,I)$$<br>logistic sigmoid函数将线性函数的输出压缩进区间(0,1)。该值可以解释为概率：$$p(y=1|x;\theta)=\sigma(\theta^{T}x)$$<br>最大化对数似然来搜索最优解。</p>
<h3 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h3><p>支持向量机模型：支持向量机不输出概率，只输出类别。当$w^{T}x+b$为正时，支持向量机预测属于正类。类似地，当当$w^{T}x+b$为负时，支持向量机预测属于负类。<br>支持向量机的一个重要创新是核技巧。学习算法重写为这种形式允许我们将$x$替换为。<br>核技巧十分强大有两大原因：</p>
<ul>
<li>使我们能够使用保证有效收敛的凸优化技术来学习作为$x$的函数的非线性模型。即优化算法可以将决策函数视为不同空间中的线性函数。</li>
<li>核函数k的实现方法通常有比直接构建$\theta(x)$再算点积高效很多。<br>最常用的核函数是高斯核</li>
</ul>
<h3 id="其他简单的监督学习算法"><a href="#其他简单的监督学习算法" class="headerlink" title="其他简单的监督学习算法"></a>其他简单的监督学习算法</h3><p>k-近邻、决策树</p>
<h2 id="无监督学习算法"><a href="#无监督学习算法" class="headerlink" title="无监督学习算法"></a>无监督学习算法</h2><p>无监督学习是指从不需要人为注释样本的分布中抽取信息的大多数尝试。该术语通常与密度估计相关，学习从分布中采样，学习从分布中去噪，需要数据分布的流形，或是将数据中相关的样本聚类。一个经典的无监督学习任务是找到数据的“最佳”表示。</p>
<ul>
<li>低维表示：尝试将x中的信息尽可能压缩在一个较小的表示中。</li>
<li>稀疏表示：通常用于需要增加表示维数的情况，使得大部分为零的表示不会丢失很多信息。这会使得表示的整体结构倾向于将数据分布在表示空间的坐标轴上。</li>
<li>独立表示：试图解开数据分布中变动的来源，使得表示的维度是统计独立的。</li>
</ul>
<h3 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h3><h3 id="k-均值聚类"><a href="#k-均值聚类" class="headerlink" title="k-均值聚类"></a>k-均值聚类</h3><h2 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a>随机梯度下降</h2><h2 id="构建机器学习算法"><a href="#构建机器学习算法" class="headerlink" title="构建机器学习算法"></a>构建机器学习算法</h2><h2 id="推动深度学习的挑战"><a href="#推动深度学习的挑战" class="headerlink" title="推动深度学习的挑战"></a>推动深度学习的挑战</h2><h3 id="维度灾难"><a href="#维度灾难" class="headerlink" title="维度灾难"></a>维度灾难</h3><p>一组变量的不同可能配置数量随着变量数目的增加而指数级增长。</p>
<h3 id="局部不变性和平滑正则化"><a href="#局部不变性和平滑正则化" class="headerlink" title="局部不变性和平滑正则化"></a>局部不变性和平滑正则化</h3><h3 id="流形学习"><a href="#流形学习" class="headerlink" title="流形学习"></a>流形学习</h3><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/exacity/deeplearningbook-chinese" target="_blank" rel="external">Deep Learning Book</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;机器学习本质上属于应用统计学，更多关注于如何用计算机统计地估计复杂函数，不太关注这些函数的置信区间。&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="知识储备" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/"/>
    
    
      <category term="Book" scheme="http://luxialan.com/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>【深度学习】 读书笔记 肆 数值计算</title>
    <link href="http://luxialan.com/2017/02/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E8%82%86-%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/"/>
    <id>http://luxialan.com/2017/02/13/【深度学习】-读书笔记-肆-数值计算/</id>
    <published>2017-02-13T11:08:27.000Z</published>
    <updated>2017-02-16T06:47:00.932Z</updated>
    
    <content type="html"><![CDATA[<p>机器学习算法需要数值计算的方法来迭代求解无解析解的数学问题。包括优化和线性方程组求解。<br><a id="more"></a></p>
<ul>
<li>1.上溢和下溢</li>
<li>2.病态条件数</li>
<li>3.基于梯度的优化方法</li>
<li>4.约束优化</li>
<li>5.实例：线性最小二乘</li>
</ul>
<h2 id="上溢和下溢"><a href="#上溢和下溢" class="headerlink" title="上溢和下溢"></a>上溢和下溢</h2><p>在数字计算机上实现连续数学的根本困难是，我们需要通过有限数量的位模式来表示无限多的实数。<br>一种特别地毁灭性舍入误差是下溢(underflow)，当接近零的数被四舍五入为零时发生下溢。<br>另一种极具破坏力的数值错误形式是上溢。当大量级的数被近似为$\infty$<br>必须对上溢和下溢进行数值稳定的一个例子是\bm{softmax函数}(softmax function)。softmax 函数经常用于预测与多项式分布相关的概率，定义为：<br>$$softmax(\bold{x})_i=/frac{exp(x<em>i)}{\sum</em>{j=1}^{n}exp(x_j)}$$</p>
<h2 id="病态条件数"><a href="#病态条件数" class="headerlink" title="病态条件数"></a>病态条件数</h2><p>条件数表明函数相对于输入的微小变化而变化的快慢程度。输入被轻微扰动而迅速改变的函数对于科学计算来说是可能是有问题的，因为输入中的舍入误差可能导致输出的巨大变化。<br>考虑$f(x)=A^{-1}x$。当$A\in\mathbb{R}^(nXn)$具有特征分解时，其条件数为$max_{i,j}|{/frac{\lambda_i}{\lambda_j}}|$<br>这是最大和最小特征值的模的比。当该数很大时，矩阵求逆对输入的误差特别敏感。</p>
<h2 id="基于梯度的优化方法"><a href="#基于梯度的优化方法" class="headerlink" title="基于梯度的优化方法"></a>基于梯度的优化方法</h2><p>我们把最大化或最小化的函数称为目标函数或准则。<br>导数<br>临界点或驻点</p>
<h2 id="基于梯度的优化方法-1"><a href="#基于梯度的优化方法-1" class="headerlink" title="基于梯度的优化方法"></a>基于梯度的优化方法</h2><h2 id="约束优化"><a href="#约束优化" class="headerlink" title="约束优化"></a>约束优化</h2><h2 id="实例：线性最小二乘"><a href="#实例：线性最小二乘" class="headerlink" title="实例：线性最小二乘"></a>实例：线性最小二乘</h2><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/exacity/deeplearningbook-chinese" target="_blank" rel="external">Deep Learning Book</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;机器学习算法需要数值计算的方法来迭代求解无解析解的数学问题。包括优化和线性方程组求解。&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="知识储备" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/"/>
    
    
      <category term="Book" scheme="http://luxialan.com/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>【深度学习】 读书笔记 叁 概率与信息论</title>
    <link href="http://luxialan.com/2017/02/12/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E5%8F%81-%E6%A6%82%E7%8E%87%E4%B8%8E%E4%BF%A1%E6%81%AF%E8%AE%BA/"/>
    <id>http://luxialan.com/2017/02/12/【深度学习】-读书笔记-叁-概率与信息论/</id>
    <published>2017-02-12T10:35:13.000Z</published>
    <updated>2017-02-15T12:56:32.091Z</updated>
    
    <content type="html"><![CDATA[<p>概率论使我们能够作出不确定的陈述以及在不确定性存在的情况下推理，而信息论使我们能够量化概率分布中的不确定性总量。<br><a id="more"></a></p>
<h2 id="为什么要用概率？"><a href="#为什么要用概率？" class="headerlink" title="为什么要用概率？"></a>为什么要用概率？</h2><p>世界是不确定的，要对世界中的活动进行建模需要用概率论来量化不确定性。<br>不确定性有三种可能的来源：</p>
<ul>
<li>被建模系统内在的随机性。</li>
<li>不完全观测。即使是确定的系统，当我们不能观测到所有驱动系统行为的变量时，该系统也会呈现随机性。</li>
<li>不完全建模。使用一些必须舍弃某些观测信息的建模时，舍弃的信息会导致模型的预测出现不确定性。</li>
</ul>
<p>在很多情况下，使用一些简单而不确定的原则要比复杂而确定的原则更为实用，即使真实的规则是确定的并且我们的模型系统对适应复杂规则具有很好的逼真度。<br>有两种概率，一种概率，直接与事件发生的频率相联系，称为频率概率；另一种概率，涉及到确定性水平，被称为贝叶斯概率。</p>
<h2 id="随机变量"><a href="#随机变量" class="headerlink" title="随机变量"></a>随机变量</h2><p>随机变量(random variable)是可以随机地取不同值的变量。<br>一种随机变量只是对可能的状态的描述；它必须伴随着一个概率分布来指定每个状态的可能性。</p>
<h2 id="概率分布"><a href="#概率分布" class="headerlink" title="概率分布"></a>概率分布</h2><p>概率分布(probability distribution)用来描述随机变量或一簇随机变量在每一个可能取到的状态的可能性大小。</p>
<h3 id="离散型变量和概率分布律函数"><a href="#离散型变量和概率分布律函数" class="headerlink" title="离散型变量和概率分布律函数"></a>离散型变量和概率分布律函数</h3><p>离散型变量的概率分布可以用概率分布律函数(probability mass function,PMF)来描述。我们通常用$P$来表示概率分布律函数。用$x$~$P(x)$表示随机变量x服从P分布。<br>概率分布律函数可以同时作用于多个随机变量。这种多个变量的概率分布被称为联合概率分布(joint probability distribution)。</p>
<h3 id="连续型变量和概率密度函数"><a href="#连续型变量和概率密度函数" class="headerlink" title="连续型变量和概率密度函数"></a>连续型变量和概率密度函数</h3><h2 id="边缘概率"><a href="#边缘概率" class="headerlink" title="边缘概率"></a>边缘概率</h2><p>我们知道了一组变量的联合概率分布，想要了解其中一个子集的概率分布。这种定义在子集上的概率分布被称为边缘概率分布(marginal probability)。对于连续型变量，我们需要用积分替代求和：$$p(x)=\int p(x,y)dy$$</p>
<h2 id="条件概率"><a href="#条件概率" class="headerlink" title="条件概率"></a>条件概率</h2><p>$P($y$=y)|$x$=x)=/fra{P(/bm{y}=y,/bm{x}=x)}{P(\bm{x}=x)}$</p>
<h2 id="条件概率的链式法则"><a href="#条件概率的链式法则" class="headerlink" title="条件概率的链式法则"></a>条件概率的链式法则</h2><h2 id="独立性和条件独立性"><a href="#独立性和条件独立性" class="headerlink" title="独立性和条件独立性"></a>独立性和条件独立性</h2><h2 id="期望，方差和协方差"><a href="#期望，方差和协方差" class="headerlink" title="期望，方差和协方差"></a>期望，方差和协方差</h2><h2 id="常用概率分布"><a href="#常用概率分布" class="headerlink" title="常用概率分布"></a>常用概率分布</h2><h3 id="Bernoulli分布"><a href="#Bernoulli分布" class="headerlink" title="Bernoulli分布"></a>Bernoulli分布</h3><ul>
<li>$P(\bm{x}=x)=/phi^x(1-/phi)^{1-x}$</li>
<li>$P(\bm{x}=0)=1-/phi</li>
<li>$P(\bm{x}=1)=/phi$</li>
<li>$\mathbb{E}_x=/phi$</li>
<li>$Var_x(x)=/phi(1-/phi)$</li>
</ul>
<h3 id="多项式分布"><a href="#多项式分布" class="headerlink" title="多项式分布"></a>多项式分布</h3><h3 id="高斯分布-正态分布"><a href="#高斯分布-正态分布" class="headerlink" title="高斯分布/正态分布"></a>高斯分布/正态分布</h3><h3 id="指数分布和Laplace分布"><a href="#指数分布和Laplace分布" class="headerlink" title="指数分布和Laplace分布"></a>指数分布和Laplace分布</h3><h3 id="Dirac分布和经验分布"><a href="#Dirac分布和经验分布" class="headerlink" title="Dirac分布和经验分布"></a>Dirac分布和经验分布</h3><h3 id="分布的混合"><a href="#分布的混合" class="headerlink" title="分布的混合"></a>分布的混合</h3><h2 id="常用函数的一些性质"><a href="#常用函数的一些性质" class="headerlink" title="常用函数的一些性质"></a>常用函数的一些性质</h2><h2 id="贝叶斯规则"><a href="#贝叶斯规则" class="headerlink" title="贝叶斯规则"></a>贝叶斯规则</h2><h2 id="连续型变量的技术细节"><a href="#连续型变量的技术细节" class="headerlink" title="连续型变量的技术细节"></a>连续型变量的技术细节</h2><h2 id="信息论"><a href="#信息论" class="headerlink" title="信息论"></a>信息论</h2><p>信息论是应用数学的一个分支，主要研究的是对一个信号能够提供的多少进行量化。<br>信息论的基本想法是一个不太可能的事件居然发生了，要比一个非常可能的事件发生，能提供更多的信息。</p>
<ul>
<li>非常可能发生的事件信息量比较少，并且极端情况下，确保能够发生的事件应该没有信息量。</li>
<li>更不可能发生的事件要具有更高的信息量</li>
<li>独立事件应具有增量的信息。例如，投掷的硬币两次正面朝上传递的信息量应该是投掷一次硬币正面朝上的信息量的两倍。</li>
</ul>
<p>为了满足上述三个性质，我们定义一个事件$\rm{x}=x$的自信息(self-information)为$$I(x)=-logP(x)$$<br>我们定义$I(x)$单位是奈特(nats)。一奈特是以$/frac{1}{\epsilon}$的概率观测到一个事件时获得的信息量。<br>自信息只处理单个的输出，我们可以用香农熵(Shannon entropy)来对整个概率分布中的不确定性总量进行量化：<br>$H(x)=\mathbb{E}<em>{x~P}[I(x)]=-\mathbb{E}</em>{x~P}[logP(x)]$</p>
<h2 id="14-结构化概率模型"><a href="#14-结构化概率模型" class="headerlink" title="14.结构化概率模型"></a>14.结构化概率模型</h2><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/exacity/deeplearningbook-chinese" target="_blank" rel="external">Deep Learning Book</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;概率论使我们能够作出不确定的陈述以及在不确定性存在的情况下推理，而信息论使我们能够量化概率分布中的不确定性总量。&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="知识储备" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/"/>
    
    
      <category term="Book" scheme="http://luxialan.com/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>【深度学习】 读书笔记 贰 线性代数</title>
    <link href="http://luxialan.com/2017/02/09/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E8%B4%B0-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    <id>http://luxialan.com/2017/02/09/【深度学习】-读书笔记-贰-线性代数/</id>
    <published>2017-02-09T11:56:12.000Z</published>
    <updated>2017-02-15T12:46:54.929Z</updated>
    
    <content type="html"><![CDATA[<p>代数、分析、几何、概率论，数学的基础知识。<br><a id="more"></a></p>
<ul>
<li>1.标量、向量、矩阵和张量</li>
<li>2.矩阵和向量相乘</li>
<li>3.单位矩阵和逆矩阵</li>
<li>4.线性相关和生成子空间</li>
<li>5.范数</li>
<li>6.特殊类型的矩阵和向量</li>
<li>7.特征分解</li>
<li>8.奇异值分解</li>
<li>9.Moore-Penrose伪逆</li>
<li>10.迹运算</li>
<li>11.行列式</li>
<li>12.主成分分析</li>
</ul>
<h2 id="标量、向量、矩阵和张量"><a href="#标量、向量、矩阵和张量" class="headerlink" title="标量、向量、矩阵和张量"></a>标量、向量、矩阵和张量</h2><p>标量：一个标量就是一个单独的数。<br>向量：一个向量是一列数。<br>矩阵：矩阵是二维数组。<br>张量：在某些情况下，我们会讨论不只两维坐标的数组。一般地，一组数组中的元素分布在若干维坐标的规则网格中，我们将其称之为张量。</p>
<h2 id="矩阵和向量相乘"><a href="#矩阵和向量相乘" class="headerlink" title="矩阵和向量相乘"></a>矩阵和向量相乘</h2><p>矩阵乘法</p>
<ul>
<li>$A(B+C)=AB+AC$</li>
<li>$A(BC)=(AB)C$</li>
<li>$(AB)^{T}=B^{T}A^{T}$<br>通过矩阵和向量来表示线性方程组</li>
<li>$Ax=b$</li>
</ul>
<h2 id="单位矩阵和逆矩阵"><a href="#单位矩阵和逆矩阵" class="headerlink" title="单位矩阵和逆矩阵"></a>单位矩阵和逆矩阵</h2><p>单位矩阵：任意向量和单位矩阵相乘，都不会改变。形式上，$I_n\in \mathtt{R} $,<br>$$\forall x\in \mathtt{R}, I_n x = x$$<br>单位矩阵结构简单：所有沿着主对角线的元素都是1，而其他位置的元素都是0，如<br>$$<br>\begin{bmatrix}<br>1 &amp; 0 &amp; 0 \<br>0 &amp; 1 &amp; 0 \<br>0 &amp; 0 &amp; 1 \<br>\end{bmatrix}<br>$$</p>
<h2 id="范数"><a href="#范数" class="headerlink" title="范数"></a>范数</h2><p>范数用来衡量向量的大小，是将向量映射到非负值的函数。<br>$L^p$范数定义如下：$$ ||x||_p=(\sum_i|x_i|^{p})^{\frac{1}{p}}$$<br>其中$p\in \mathtt{R},$p \geq 1$<br>范数可以是满足下列性质的任意函数：</p>
<ul>
<li>$f(x)=0$ =&gt; $x=0$</li>
<li>$f(x+y) \leq f(x) + f(y)$</li>
<li>$\forall \alpha \in \mathtt{R}, f(\alpha)=|\alpha|f(x)$ 当$p=2$时</li>
</ul>
<h3 id="特征分解"><a href="#特征分解" class="headerlink" title="特征分解"></a>特征分解</h3><p>我们可以通过分解质因数来发现一些关于整数的真实性质，我们也可以通过分解矩阵来获取矩阵表示成数组元素时不明显的函数性质。<br>特征分解是使用最广的矩阵分解之一，即我们将矩阵分解成一组特征向量和特征值。<br>方阵$A$的特征向量是指与$A$相乘后相当于对该向量进行放缩的非零向量：<br>$$Av=\lambda v$$<br>标量$\lambda$称为这个特征向量对应的特征值。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/exacity/deeplearningbook-chinese" target="_blank" rel="external">Deep Learning Book</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;代数、分析、几何、概率论，数学的基础知识。&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="知识储备" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/"/>
    
    
      <category term="Book" scheme="http://luxialan.com/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>【深度学习】 读书笔记 壹 深度学习概述</title>
    <link href="http://luxialan.com/2017/02/09/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E5%A3%B9-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0/"/>
    <id>http://luxialan.com/2017/02/09/【深度学习】-读书笔记-壹-深度学习概述/</id>
    <published>2017-02-09T05:56:12.000Z</published>
    <updated>2017-02-13T13:27:58.072Z</updated>
    
    <content type="html"><![CDATA[<p>深度学习的前世今生。<br><a id="more"></a></p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>AI深度学习：层次化的概念让计算机构建较简单的概念来学习复杂概念。如果绘制出这些概念如何建立在彼此之上的图，我们将得到一张“深”（层次很多）的图。出于这个原因，我们称这种方法为AI深度学习。</p>
<p>知识图谱(knowledge base)方法: 计算机可以通过这些形式化语言自动地使用逻辑推理规则来理解声明。</p>
<p>机器学习(machine learning): Al系统需要具备自己获取知识的能力，即从原始数据中提取模式的能力，这种能力称为机器学习。例如：逻辑回归(logistic regression)和朴素贝叶斯(naive Bayes)。</p>
<p>表示学习(representation learning): 使用机器学习来发现数据的表示(representation)本身。例子： 自动编码器(autoencoder)：输入–&gt;编码器(encoder)–&gt;表示–&gt;解码器(decoder)。</p>
<p>深度学习(deep learning): 让计算机通过简单概念构建复杂的概念。例子： 前馈深度网络或多层感知机(multilayer perceptron, MLP)。深度学习是AI的途径之一，可以用来学习数据的正确表达和一个多步骤的计算机程序。</p>
<p><center> <img src="/images/deep_learning_book/concept.png" alt="Alt text"></center></p>
<h2 id="深度学习的历史趋势"><a href="#深度学习的历史趋势" class="headerlink" title="深度学习的历史趋势"></a>深度学习的历史趋势</h2><ul>
<li>1.数据量越来越大。</li>
<li>2.针对深度学习的计算机软硬件设施有所改善，深度学习模型的规模也随之增长。</li>
<li>3.深度学习已经解决日益复杂的应用，并且精度不断提高。<h3 id="深度学习的三次浪潮"><a href="#深度学习的三次浪潮" class="headerlink" title="深度学习的三次浪潮"></a>深度学习的三次浪潮</h3></li>
<li>1.第一次浪潮开始于20世纪40年代到20世纪60年代的控制论，随着生物学习理论的发展和第一个模型的实现（感知机）,能实现单个神经元的训练。</li>
<li>2.第二次浪潮开始于1980-1995年间的链接机制方法，可以使用反向链接训练具有一两个隐藏层的神经网络。</li>
<li>3.第三次浪潮，深度学习，大约始于2006年。</li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/exacity/deeplearningbook-chinese" target="_blank" rel="external">Deep Learning Book</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;深度学习的前世今生。&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="知识储备" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/"/>
    
    
      <category term="Book" scheme="http://luxialan.com/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>服务器集群搭建与运维技术指南</title>
    <link href="http://luxialan.com/2016/12/29/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%9B%86%E7%BE%A4%E6%8C%87%E5%8D%97/"/>
    <id>http://luxialan.com/2016/12/29/服务器集群指南/</id>
    <published>2016-12-29T02:07:09.000Z</published>
    <updated>2017-01-22T13:58:52.711Z</updated>
    
    <content type="html"><![CDATA[<p>研究生期间协助导师搭建和管理实验室的服务器，其中涉及到基础的服务器集群搭建、管理和维护。由于时间有限，只总结出一个大的框架，仅供参考。<br><a id="more"></a></p>
<h2 id="服务器集群搭建"><a href="#服务器集群搭建" class="headerlink" title="服务器集群搭建"></a>服务器集群搭建</h2><h3 id="服务集群拓扑图"><a href="#服务集群拓扑图" class="headerlink" title="服务集群拓扑图"></a>服务集群拓扑图</h3><p><center> <img src="/images/server/server_topology.png" alt="Alt text"></center><br>一个服务器集群应当有一台以上的数据中心存储数据Data Server，Data Server特点是存储量尽可能大而运算能力可以不必太高，另外多台服务器作为运行程序的Work Server,根据不同的需求配置Work Server.</p>
<h2 id="服务器集群管理"><a href="#服务器集群管理" class="headerlink" title="服务器集群管理"></a>服务器集群管理</h2><h3 id="Linux服务器管理三步曲"><a href="#Linux服务器管理三步曲" class="headerlink" title="Linux服务器管理三步曲"></a>Linux服务器管理三步曲</h3><ul>
<li>1.初学乍道：Linux基本知识</li>
<li>2.初窥门径：Shell脚本编程</li>
<li>3.登堂入室：Pssh并行管理</li>
</ul>
<h4 id="1-初学乍道：Linux基本知识"><a href="#1-初学乍道：Linux基本知识" class="headerlink" title="1.初学乍道：Linux基本知识"></a>1.初学乍道：Linux基本知识</h4><p>linux的常用的命令如下：<br>查看服务器基本信息<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ top</div></pre></td></tr></table></figure></p>
<p><center> <img src="/images/server/top.png" alt="Alt text"></center><br>top的升级版<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ htop</div></pre></td></tr></table></figure></p>
<p><center> <img src="/images/server/htop.png" alt="Alt text"></center><br>查看当前目录下文件信息<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ ls</div></pre></td></tr></table></figure></p>
<p>更改目录<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ <span class="built_in">cd</span></div></pre></td></tr></table></figure></p>
<p>新建文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ mkdir</div></pre></td></tr></table></figure></p>
<p>删除文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ rm</div></pre></td></tr></table></figure></p>
<p>复制文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ cp</div></pre></td></tr></table></figure></p>
<p>移动文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ mv</div></pre></td></tr></table></figure></p>
<p>查找文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ find</div></pre></td></tr></table></figure></p>
<p>切换用户<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ su root</div><div class="line">Password:</div><div class="line">root@grus:/home/luxi<span class="comment">#</span></div></pre></td></tr></table></figure></p>
<p>更改文件使用权限<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ chmod</div></pre></td></tr></table></figure></p>
<p>挂载<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ mount</div></pre></td></tr></table></figure></p>
<p>远程登录其他服务器<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ ssh</div></pre></td></tr></table></figure></p>
<p>更多基本基本命令参考<a href="http://cn.linux.vbird.org/" target="_blank" rel="external">《鸟哥的私房菜》</a></p>
<h4 id="2-初窥门径：Shell脚本编程"><a href="#2-初窥门径：Shell脚本编程" class="headerlink" title="2.初窥门径：Shell脚本编程"></a>2.初窥门径：Shell脚本编程</h4><p>Shell脚本编程可以看做为基本命令组合而成的复杂命令，其存在的价值在于封装好复杂命令，使用户能够通过运行脚本来执行复杂命令，避免了重复编程。是自动化管理服务器的重要一步。</p>
<h4 id="3-登堂入室：Pssh并行管理"><a href="#3-登堂入室：Pssh并行管理" class="headerlink" title="3.登堂入室：Pssh并行管理"></a>3.登堂入室：Pssh并行管理</h4><p><a href="https://code.google.com/archive/p/parallel-ssh/" target="_blank" rel="external">PSSH(parallel-ssh)</a>是一个python编写的在多台服务器上执行命令的轻量级管理工具。其实运用Shell脚本语言，我们完全可以自己从头实现一个类似的工具（通过ssh+特定命令），然而可以避免重复造轮子的话还是尽量避免。<br>例子：pssh实现查看多台服务器运行情况</p>
<p><center> <img src="/images/server/pssh.png" alt="Alt text"></center></p>
<h2 id="服务器集群维护"><a href="#服务器集群维护" class="headerlink" title="服务器集群维护"></a>服务器集群维护</h2><p><a href="https://wiki.tankywoo.com/#tool" target="_blank" rel="external">常用工具</a></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>个人感觉服务器集群的搭建和维护的三个核心是监控、安全和自动化。</p>
<ul>
<li>1.监控指的是能及时的获取服务器集群的信息并从中发现异常。</li>
<li>2.安全指的服务器集群数据的权限管理和备份管理。</li>
<li>2.自动化指的是服务器集群的管理和维护应该借助工具和脚本避免重复造轮子。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;研究生期间协助导师搭建和管理实验室的服务器，其中涉及到基础的服务器集群搭建、管理和维护。由于时间有限，只总结出一个大的框架，仅供参考。&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="技术管理" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E6%8A%80%E6%9C%AF%E7%AE%A1%E7%90%86/"/>
    
    
      <category term="Technique" scheme="http://luxialan.com/tags/Technique/"/>
    
  </entry>
  
</feed>
