<!DOCTYPE html><html lang="zh-Hans"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="每天进步一点点"><title>《深度学习》 笔记 伍 机器学习基础 | 水冼雪</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/6.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.2.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">《深度学习》 笔记 伍 机器学习基础</h1><a id="logo" href="/.">水冼雪</a><p class="description">抬头看天，低头赶路</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">《深度学习》 笔记 伍 机器学习基础</h1><div class="post-meta">Feb 14, 2017<span> | </span><span class="category"><a href="/categories/学习/">学习</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><a href="/2017/02/14/《深度学习》-笔记-伍-机器学习基础/#comments" class="ds-thread-count cloud-tie-join-count"><span style="font-size: 15px; color: #6E7173;" class="join-count">0</span><span> 条参与</span></a><div class="post-content"><p>机器学习本质上属于应用统计学，更多关注于如何用计算机统计地估计复杂函数，不太关注这些函数的置信区间。<br><a id="more"></a></p>
<ul>
<li>1.学习算法</li>
<li>2.容量、过拟合和欠拟合</li>
<li>3.超参数和验证集</li>
<li>4.估计、偏差和方差</li>
<li>5.最大似然估计</li>
<li>6.贝叶斯统计</li>
<li>7.监督学习方法</li>
<li>8.无监督学习方法</li>
<li>9.随机梯度下降</li>
<li>10.构建机器学习算法</li>
<li>11.推动机深度学习的挑战</li>
</ul>
<h2 id="学习算法"><a href="#学习算法" class="headerlink" title="学习算法"></a>学习算法</h2><p>对于某类任务$T$和性能度量$P$,一个计算机程序被认为可以从经验$E$中学习是指，通过经验E改进后，它在任务$T$上由性能度量$P$衡量的性能有所提升。</p>
<h3 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h3><ul>
<li>分类</li>
<li>输入缺失分类</li>
<li>回归</li>
<li>转录</li>
<li>机器翻译</li>
<li>结构化输出</li>
<li>异常检测</li>
<li>合成和采样</li>
<li>缺失值填补</li>
<li>去噪</li>
<li>密度估计或概率分布律函数估计</li>
</ul>
<h3 id="性能度量，-P"><a href="#性能度量，-P" class="headerlink" title="性能度量，$P$"></a>性能度量，$P$</h3><ul>
<li>准确率</li>
<li>错误率</li>
<li>测试集</li>
</ul>
<h3 id="经验"><a href="#经验" class="headerlink" title="经验"></a>经验</h3><ul>
<li>无监督学习算法</li>
<li>有监督学习算法</li>
</ul>
<h3 id="实例-线性回归"><a href="#实例-线性回归" class="headerlink" title="实例:线性回归"></a>实例:线性回归</h3><p>目标是建立一个系统，将向量$x\in\mathbb{R}^n$作为输入，预测标量$y\in \mathbb{R}$作为输出。线性回归的输出是其输入的线性函数。</p>
<h2 id="容量，过拟合和欠拟合"><a href="#容量，过拟合和欠拟合" class="headerlink" title="容量，过拟合和欠拟合"></a>容量，过拟合和欠拟合</h2><h3 id="泛化"><a href="#泛化" class="headerlink" title="泛化"></a>泛化</h3><p>在未观测到的输入上表现良好的能力被称为泛化(generalization).</p>
<h3 id="性能的测量"><a href="#性能的测量" class="headerlink" title="性能的测量"></a>性能的测量</h3><p>训练误差，泛化误差\测试误差</p>
<h3 id="独立同分布假设"><a href="#独立同分布假设" class="headerlink" title="独立同分布假设"></a>独立同分布假设</h3><p>该假设是说，每个数据集中的样本都是彼此相互独立的，并且训练集和测试集是同分布的，其上数据采样自相同的分布。这个假设使我们能够在单个样本上用概率分布描述数据生成过程。然后相同的分布可以用来生成每一个训练样本和每一个测试样本。<br>测试误差期望会大于或等于训练误差期望。以下是决定机器学习算法效果是否好的因素：</p>
<ul>
<li>降低训练误差</li>
<li>缩小训练误差和测试误差的差距<br>这两个因素对应机器学习的两个主要挑战。</li>
<li>欠拟合。欠拟合发生在模型不能再训练集上获得足够的误差。</li>
<li>过拟合。过拟合发生在训练误差和测试误差之间的差距过大。</li>
</ul>
<h3 id="容量"><a href="#容量" class="headerlink" title="容量"></a>容量</h3><p>模型的容量是指其拟合各种函数的能力。容量低的模型可能很难拟合训练集。容量高的模型可能会过拟合，因为记住了不适用于测试集的训练集性质。</p>
<h3 id="控制容量"><a href="#控制容量" class="headerlink" title="控制容量"></a>控制容量</h3><p>一种控制训练算法容量的方法是选择假设空间，即能够选为解决方案的学习算法函数集。例如，线性回归函数将关于其输入的所有线性函数作为假设空间。广义线性回归的假设空间包括多项式函数，而非仅有线性函数。</p>
<h3 id="奥卡姆剃刀-Occam’s-razor"><a href="#奥卡姆剃刀-Occam’s-razor" class="headerlink" title="奥卡姆剃刀(Occam’s razor)"></a>奥卡姆剃刀(Occam’s razor)</h3><p>统计学习理论提供了量化模型容量的不同方法。在这些中，最有名的是${Vapnik-Chervonenkis}$维度。VC维定义为该分类器能够分类的训练样本的最大数目。</p>
<h3 id="没有免费午餐定理。"><a href="#没有免费午餐定理。" class="headerlink" title="没有免费午餐定理。"></a>没有免费午餐定理。</h3><p>在所有可能的数据生成分布上平均，每一个分类算法在未事先观测的点上都有相同的错误率。换言之，在某种意义上，没有一个机器学习算法总是比其他的要好。<br>幸运的是，这些结论仅在我们考虑所有可能的数据生成分布时才成立。对遇到的概率分布进行假设的话，那么我们可以设计在这些分布上效果良好的学习算法。这意味着机器学习研究的目标不是找一个通用学习算法或是绝对最好的学习算法。我们的目标是理解什么样的分布和人工智能获取经验的“真实世界”相关，什么样的学习算法在我们关注的数据生成分布上效果最好。</p>
<h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><p>没有免费午餐定理暗示我们必须在特定任务上设计性能良好的机器学习算法。当这些偏好和我们希望算法解决的学习问题相吻合时，性能会更好。<br>算法的效果不仅受影响于假设空间的函数数量，也取决于这些函数的具体形式。可以通过控制允许采样的函数种类的方式，也可以通过控制这些函数的数量的方式。</p>
<h2 id="超参数和验证集"><a href="#超参数和验证集" class="headerlink" title="超参数和验证集"></a>超参数和验证集</h2><h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><p>在原始数据上随机采样或分离出的不同数据集上重复训练和测试的想法。最常见的是$k$-折交叉验证过程：</p>
<ul>
<li>将数据集分成k个不重合的子集。测试误差可以估计为$k$次计算后的平均测试误差。在第$i$次测试时，数据的第$i$个子集用于测试集，其他的数据用于训练集。</li>
</ul>
<h2 id="估计，偏差和方差"><a href="#估计，偏差和方差" class="headerlink" title="估计，偏差和方差"></a>估计，偏差和方差</h2><p>统计领域为我们提供了很多工具用于实现机器学习目标，不仅可以解决训练集上的任务，还可以泛化。基本的概念，例如参数估计，偏差和方差，对于形式化刻画泛化，欠拟合和过拟合都非常有帮助。</p>
<h3 id="点估计"><a href="#点估计" class="headerlink" title="点估计"></a>点估计</h3><p>点估计试图为一些感兴趣的量提供单个“最优”预测。一般地，感兴趣的量可以是单个参数，或是某些参数模型中的一个向量参数。<br>为了区分参数估计和真实值，我们习惯表示参数$\theta$的点估计为$\hat{\theta}$<br>让${x^{1},…,x^{m}}$是m个独立同分布的数据点。点估计或统计量是这些数据的任意函数：<br>$$\hat{\theta_m}=g(x^{(1)},…,x^{(m)})$$<br>一个好的估计量的输出会接近生成训练数据的真实参数$/theta$。<br>点估计也可以指输入和目标变量之间关系的估计。我们将这类点估计称为函数估计。</p>
<h3 id="偏差"><a href="#偏差" class="headerlink" title="偏差"></a>偏差</h3><p>估计的偏差：$bias(\hat{\theta_m})=\mathbb{E}(\hat{\theta_m})-\theta$<br>无偏：$\mathbb{E}(\hat{\theta<em>m})=\theta$<br>渐近无偏：$lim</em>{m-\mapsto\infty}\mathbb{E}(\hat{\theta_m})=\theta$</p>
<h3 id="方差和标准误差"><a href="#方差和标准误差" class="headerlink" title="方差和标准误差"></a>方差和标准误差</h3><p>数据样本函数的变化程度。计算估计量的期望来决定他的偏差。<br>估计量的方差</p>
<h2 id="监督学习算法"><a href="#监督学习算法" class="headerlink" title="监督学习算法"></a>监督学习算法</h2><h3 id="概率监督学习"><a href="#概率监督学习" class="headerlink" title="概率监督学习"></a>概率监督学习</h3><p>本书的大部分监督学习算法都是基于估计概率分布$p(y|x)$。我们可以使用最大似然估计找到对于有参分布族$p(y|x,\theta)$最好的参数向量$\theta$<br>$$p(y|x,\theta)=N(y;\theta^{T}x,I)$$<br>logistic sigmoid函数将线性函数的输出压缩进区间(0,1)。该值可以解释为概率：$$p(y=1|x;\theta)=\sigma(\theta^{T}x)$$<br>最大化对数似然来搜索最优解。</p>
<h3 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h3><p>支持向量机模型：支持向量机不输出概率，只输出类别。当$w^{T}x+b$为正时，支持向量机预测属于正类。类似地，当当$w^{T}x+b$为负时，支持向量机预测属于负类。<br>支持向量机的一个重要创新是核技巧。<br>核技巧十分强大有两大原因：</p>
<ul>
<li>使我们能够使用保证有效收敛的凸优化技术来学习作为$x$的函数的非线性模型。即优化算法可以将决策函数视为不同空间中的线性函数。</li>
<li>核函数k的实现方法通常有比直接构建$\theta(x)$再算点积高效很多。<br>最常用的核函数是高斯核</li>
</ul>
<h3 id="其他简单的监督学习算法"><a href="#其他简单的监督学习算法" class="headerlink" title="其他简单的监督学习算法"></a>其他简单的监督学习算法</h3><p>k-近邻、决策树</p>
<h2 id="无监督学习算法"><a href="#无监督学习算法" class="headerlink" title="无监督学习算法"></a>无监督学习算法</h2><p>无监督学习是指从不需要人为注释样本的分布中抽取信息的大多数尝试。该术语通常与密度估计相关，学习从分布中采样，学习从分布中去噪，需要数据分布的流形，或是将数据中相关的样本聚类。一个经典的无监督学习任务是找到数据的“最佳”表示。</p>
<ul>
<li>低维表示：尝试将x中的信息尽可能压缩在一个较小的表示中。</li>
<li>稀疏表示：通常用于需要增加表示维数的情况，使得大部分为零的表示不会丢失很多信息。这会使得表示的整体结构倾向于将数据分布在表示空间的坐标轴上。</li>
<li>独立表示：试图解开数据分布中变动的来源，使得表示的维度是统计独立的。</li>
</ul>
<h3 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h3><h3 id="k-均值聚类"><a href="#k-均值聚类" class="headerlink" title="k-均值聚类"></a>k-均值聚类</h3><h2 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a>随机梯度下降</h2><h2 id="构建机器学习算法"><a href="#构建机器学习算法" class="headerlink" title="构建机器学习算法"></a>构建机器学习算法</h2><h2 id="推动深度学习的挑战"><a href="#推动深度学习的挑战" class="headerlink" title="推动深度学习的挑战"></a>推动深度学习的挑战</h2><h3 id="维度灾难"><a href="#维度灾难" class="headerlink" title="维度灾难"></a>维度灾难</h3><p>一组变量的不同可能配置数量随着变量数目的增加而指数级增长。</p>
<h3 id="局部不变性和平滑正则化"><a href="#局部不变性和平滑正则化" class="headerlink" title="局部不变性和平滑正则化"></a>局部不变性和平滑正则化</h3><h3 id="流形学习"><a href="#流形学习" class="headerlink" title="流形学习"></a>流形学习</h3><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/exacity/deeplearningbook-chinese" target="_blank" rel="external">Deep Learning Book</a></p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://luxialan.com/2017/02/14/《深度学习》-笔记-伍-机器学习基础/" data-id="cj7362x6g000ch0weh44xm21d" class="article-share-link">分享</a><div class="tags"><a href="/tags/technique/">technique</a><a href="/tags/note/">note</a></div><div class="post-nav"><a href="/2017/02/15/理财基础指南/" class="pre">理财基础指南</a><a href="/2017/02/13/《深度学习》-笔记-肆-数值计算/" class="next">《深度学习》 笔记 肆 数值计算</a></div><div id="cloud-tie-wrapper" class="cloud-tie-wrapper"></div><script>var cloudTieConfig = {
  url: document.location.href,
  productKey: "true",
  target: "cloud-tie-wrapper"
};</script><script src="https://img1.cache.netease.com/f2e/tie/yun/sdk/loader.js"></script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://luxialan.com"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/学习/">学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/技术/">技术</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/投资/">投资</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/杂谈/">杂谈</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/technique/" style="font-size: 15px;">technique</a> <a href="/tags/note/" style="font-size: 15px;">note</a> <a href="/tags/economy-finance/" style="font-size: 15px;">economy/finance</a> <a href="/tags/math/" style="font-size: 15px;">math</a> <a href="/tags/gossip/" style="font-size: 15px;">gossip</a> <a href="/tags/handbook/" style="font-size: 15px;">handbook</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/09/02/《A-Course-in-Game-Theory》-笔记/">《A Course in Game Theory》 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/26/【第三周】-做自己/">【第三周】 做自己</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/06/《简约至上：交互设计四策略》-笔记/">《简约至上：交互设计四策略》 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/02/《金钱有术》-笔记/">《金钱有术》 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/01/《量化投资方法论》-笔记/">《量化投资方法论》 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/30/【第二周】-有朋自远方来/">【第二周】 有朋自远方来</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/29/《量化投资与当前市场》-笔记/">《量化投资与当前市场》 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/18/《证券分析》-笔记/">《证券分析》 笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/12/【第一周】-逆水行舟/">【第一周】 逆水行舟</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/04/前端工程师指南/">前端工程师指南</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2017 <a href="/." rel="nofollow">水冼雪.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.0.47/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>