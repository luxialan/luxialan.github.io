<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>水冼雪</title>
  <subtitle>抬头看天，低头赶路</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://luxialan.com/"/>
  <updated>2017-07-02T12:51:32.650Z</updated>
  <id>http://luxialan.com/</id>
  
  <author>
    <name>luxialan</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>【海归交易法则】 读书笔记</title>
    <link href="http://luxialan.com/2017/07/02/%E3%80%90%E6%B5%B7%E5%BD%92%E4%BA%A4%E6%98%93%E6%B3%95%E5%88%99%E3%80%91-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <id>http://luxialan.com/2017/07/02/【海归交易法则】-读书笔记/</id>
    <published>2017-07-02T12:51:32.000Z</published>
    <updated>2017-07-02T12:51:32.650Z</updated>
    
    <summary type="html">
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>研究生这三年</title>
    <link href="http://luxialan.com/2017/07/02/%E7%A0%94%E7%A9%B6%E7%94%9F%E8%BF%99%E4%B8%89%E5%B9%B4/"/>
    <id>http://luxialan.com/2017/07/02/研究生这三年/</id>
    <published>2017-07-02T07:05:35.000Z</published>
    <updated>2017-07-02T14:11:09.425Z</updated>
    
    <content type="html"><![CDATA[<p>白煦过隙，研究生三年转眼就过了，很感谢这三年的时光，至今仍记得当年大四时抱着试一试的态度联系现在导师的忐忑心情。这三年伴随实验室一起成长，从最初的十几人扩展到现在的几十人，期间经历了不少事情，回头看由于自己的不成熟当时处理得并不是那么得当，但很幸运地，周围的人大多给予了包容和理解。遇见了值得珍惜的伙伴，对我而言是很重要的存在。同门师兄弟都有各自闪光的地方，所以时常提醒自己要多多努力，身处一个向上发展的团队中，很容易将平台的光环误以为是自身的能力。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;白煦过隙，研究生三年转眼就过了，很感谢这三年的时光，至今仍记得当年大四时抱着试一试的态度联系现在导师的忐忑心情。这三年伴随实验室一起成长，从最初的十几人扩展到现在的几十人，期间经历了不少事情，回头看由于自己的不成熟当时处理得并不是那么得当，但很幸运地，周围的人大多给予了包容
    
    </summary>
    
      <category term="随便侃侃" scheme="http://luxialan.com/categories/%E9%9A%8F%E4%BE%BF%E4%BE%83%E4%BE%83/"/>
    
      <category term="总结" scheme="http://luxialan.com/categories/%E9%9A%8F%E4%BE%BF%E4%BE%83%E4%BE%83/%E6%80%BB%E7%BB%93/"/>
    
    
      <category term="Gossip" scheme="http://luxialan.com/tags/Gossip/"/>
    
  </entry>
  
  <entry>
    <title>【程序员健康指南】 读书笔记</title>
    <link href="http://luxialan.com/2017/04/19/%E3%80%90%E7%A8%8B%E5%BA%8F%E5%91%98%E5%81%A5%E5%BA%B7%E6%8C%87%E5%8D%97%E3%80%91-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <id>http://luxialan.com/2017/04/19/【程序员健康指南】-读书笔记/</id>
    <published>2017-04-19T07:49:35.000Z</published>
    <updated>2017-04-20T00:50:28.000Z</updated>
    
    <content type="html"><![CDATA[<p>身体是程序员的本钱<br><a id="more"></a></p>
<h2 id="日常清单"><a href="#日常清单" class="headerlink" title="日常清单"></a>日常清单</h2><ul>
<li>计划：健康的站立</li>
<li>步行：每天10000步，包含20分钟快步走</li>
<li>活动：每小时5分钟活动，每20分钟改变一下姿势</li>
<li>饮食：5份水果或蔬菜</li>
<li>形体训练：5种无器械锻炼</li>
</ul>
<h2 id="头痛诱因"><a href="#头痛诱因" class="headerlink" title="头痛诱因"></a>头痛诱因</h2><ul>
<li>天气：低气压、高温、高海拔</li>
<li>荷尔蒙：月经期、怀孕期、更年期</li>
<li>感官刺激：香水、清洁用品、强光、吸烟</li>
<li>高强度体力活动：有氧锻炼、举重、脱水、性行为</li>
<li>生活方式：缺乏睡眠、压力</li>
<li>饮食方式：咖啡因、谷氨酸钠（味精）、阿斯巴甜、酒精</li>
</ul>
<h2 id="缓解头痛"><a href="#缓解头痛" class="headerlink" title="缓解头痛"></a>缓解头痛</h2><ul>
<li>灯光调暗，平躺、闭眼、放松，前额放一条浸湿的凉毛巾。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;身体是程序员的本钱&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="知识储备" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/"/>
    
    
      <category term="Book" scheme="http://luxialan.com/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>【量化交易 如何建立自己的算法交易】 读书笔记</title>
    <link href="http://luxialan.com/2017/03/07/%E3%80%90%E9%87%8F%E5%8C%96%E4%BA%A4%E6%98%93-%E5%A6%82%E4%BD%95%E5%BB%BA%E7%AB%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E7%AE%97%E6%B3%95%E4%BA%A4%E6%98%93%E3%80%91-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <id>http://luxialan.com/2017/03/07/【量化交易-如何建立自己的算法交易】-读书笔记/</id>
    <published>2017-03-07T03:25:34.000Z</published>
    <updated>2017-03-07T14:21:46.000Z</updated>
    
    <content type="html"><![CDATA[<p>量化交易，也称算法交易，是严格按照计算机算法程序给出的买卖决策进行的证券交易。<br><a id="more"></a></p>
<ul>
<li>易扩大</li>
<li>节省时间</li>
<li>营销非必需</li>
</ul>
<h2 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h2><ul>
<li>对基本策略变形</li>
<li>真正困难的地方并不是缺乏交易理念，而是缺乏甄别策略的能力。<h3 id="有效的策略"><a href="#有效的策略" class="headerlink" title="有效的策略"></a>有效的策略</h3></li>
<li>工作时间</li>
<li>编程水平</li>
<li>交易资本</li>
<li>目标<h3 id="不可行的策略"><a href="#不可行的策略" class="headerlink" title="不可行的策略"></a>不可行的策略</h3></li>
<li>策略与基准相比如何？收益持续性如何。</li>
</ul>
<p>使用夏普比率或信息比率作为量化交易策略的业绩衡量指标<br>信息比率=超额收益率的均值/超额收益率的标准差<br>超额收益率=组合收益率-基准收益率</p>
<ul>
<li>策略的年交易次数有限，夏普比率可能就不会太高。</li>
<li>策略的挫跌很大，或是挫跌时间很长，也不大可能有很高的夏普比率。<h3 id="交易成本如何影响策略"><a href="#交易成本如何影响策略" class="headerlink" title="交易成本如何影响策略"></a>交易成本如何影响策略</h3></li>
<li>交易成本不仅包括经纪商收取的佣金，还包括流动性成本。<h3 id="数据有无存活偏差"><a href="#数据有无存活偏差" class="headerlink" title="数据有无存活偏差"></a>数据有无存活偏差</h3></li>
<li>股票价格的历史数据库往往不包括那些由于破产、退市、兼并或收购而消失的股票，因此存在所谓的存货偏差。<h3 id="策略的业绩如何随时间变化而变化？"><a href="#策略的业绩如何随时间变化而变化？" class="headerlink" title="策略的业绩如何随时间变化而变化？"></a>策略的业绩如何随时间变化而变化？</h3></li>
<li>状态转换应该也被纳入复杂模型<h3 id="过拟合问题"><a href="#过拟合问题" class="headerlink" title="过拟合问题"></a>过拟合问题</h3>统计学意义上相互独立的金融数据的数量是非常有限的，有效的AI方法有以下特征。</li>
<li>基于正确的计量经济学或理论基础，而不是随机发现的模式。</li>
<li>所需的参数用到历史数据较少</li>
<li>只用到了线性回归，并未使用复杂的非线性函数</li>
<li>概念上很简单</li>
<li>所有优化都必须在不含未来未知数据的移动回顾窗口中实现，并且这种优化的效果必须不断地被未来未知的数据所证实。<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2>如何找到潜在的交易策略：</li>
<li>商学院或其他经济研究机构的网站。</li>
<li>面向零售投资者的金融网站和博客。</li>
<li>可与其他交易员交流心得的交易员论坛。<br>如何筛选策略：</li>
<li>你有多少时间可以用来完善你的交易程序</li>
<li>你的编程能力如何</li>
<li>你的资本规模有多大</li>
<li>你的目标是稳定的月度收入还是追求大额的长期资本收益？<br>合适的策略：</li>
<li>它能否跑赢基准</li>
<li>它有足够高的夏普比率吗？</li>
<li>它有足够小的挫跌和足够短的挫跌期吗？</li>
<li>回测有无存活偏差？</li>
<li>与早年相比，策略近几年不灵了吗？</li>
<li>策略具有避开基金经理激烈竞争的“特色”吗？<h2 id="回测"><a href="#回测" class="headerlink" title="回测"></a>回测</h2><h3 id="回测平台-感觉很老了"><a href="#回测平台-感觉很老了" class="headerlink" title="回测平台(感觉很老了)"></a>回测平台(感觉很老了)</h3></li>
<li>Excel</li>
<li>MATLAB</li>
<li>TradeStation<h3 id="回测数据"><a href="#回测数据" class="headerlink" title="回测数据"></a>回测数据</h3></li>
<li>注意事项一：数据是否经分拆及股息调整</li>
<li>注意事项二：数据有无存活偏差</li>
<li>注意事项三：实盘价而不是最高、最低价<h3 id="业绩度量"><a href="#业绩度量" class="headerlink" title="业绩度量"></a>业绩度量</h3><h3 id="回测陷阱"><a href="#回测陷阱" class="headerlink" title="回测陷阱"></a>回测陷阱</h3></li>
<li>前视偏差</li>
<li>数据过拟合。构建数据驱动模型时，几乎不可能消除过拟合</li>
<li>敏感性分析<h3 id="策略改进"><a href="#策略改进" class="headerlink" title="策略改进"></a>策略改进</h3></li>
<li>策略的改进，最好基于经济学基本原理，或者透彻研究过的市场现象，而不是依据一些主观的试错法则。否则，就有可能产生数据过拟合。<h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3>回测会牵扯到许多细节问题，如：</li>
<li>数据：分拆和股息的调整，日最高、最低价的噪声，存活偏差。</li>
<li>业绩度量：年化夏普比率和最大挫跌。</li>
<li>前视偏差：在过去的交易决策中使用无法得到的事后信息。</li>
<li>数据迁就偏差：拟合历史数据时使用过多参数，可以用大样本数据、样本外测试和敏感性分析来避免此类偏差。</li>
<li>交易成本：交易成本会影响策略业绩。</li>
<li>策略改进：通过策略的微小调整来优化业绩的常见方法。<h2 id="创建交易业务"><a href="#创建交易业务" class="headerlink" title="创建交易业务"></a>创建交易业务</h2>零售经纪商可以给予完全的自由和更好的资本保护，但杠杆低；自营交易公司给予的自由和资本保护较少，但杠杆高。<br>无论是选择零售经纪商还是选择自营交易公司，都要确保交易账户和系统满足以下特征：</li>
<li>相对较低的佣金</li>
<li>可交易金融工具品种广泛</li>
<li>有足够深度的流动资金池</li>
<li>最重要的是，获取实时数据和传送指令的API<br>交易员的操作环境包括：</li>
<li>一台双核或四核电脑</li>
<li>高速网络</li>
<li>防中断电源</li>
<li>实时数据和新闻来源</li>
<li>服务器托管<h2 id="自动交易系统的功能"><a href="#自动交易系统的功能" class="headerlink" title="自动交易系统的功能"></a>自动交易系统的功能</h2></li>
</ul>
<h2 id="资金和风险管理"><a href="#资金和风险管理" class="headerlink" title="资金和风险管理"></a>资金和风险管理</h2><ul>
<li>最优资本配置和杠杆</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;量化交易，也称算法交易，是严格按照计算机算法程序给出的买卖决策进行的证券交易。&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="知识储备" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/"/>
    
    
      <category term="Book" scheme="http://luxialan.com/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>【我是高频交易工程师】 读书笔记</title>
    <link href="http://luxialan.com/2017/03/04/%E3%80%90%E6%88%91%E6%98%AF%E9%AB%98%E9%A2%91%E4%BA%A4%E6%98%93%E5%B7%A5%E7%A8%8B%E5%B8%88%E3%80%91-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <id>http://luxialan.com/2017/03/04/【我是高频交易工程师】-读书笔记/</id>
    <published>2017-03-04T03:39:39.000Z</published>
    <updated>2017-03-04T13:10:58.000Z</updated>
    
    <content type="html"><![CDATA[<p>高频交易是为了增加市场流动性。<br><a id="more"></a></p>
<ul>
<li>高频交易的概念：系统、动力、理论基石</li>
<li>高频交易的技术</li>
<li>高频交易的策略</li>
<li>高频交易的职业选择</li>
</ul>
<h2 id="高频交易的概念"><a href="#高频交易的概念" class="headerlink" title="高频交易的概念"></a>高频交易的概念</h2><h3 id="高频交易系统"><a href="#高频交易系统" class="headerlink" title="高频交易系统"></a>高频交易系统</h3><ul>
<li>交易指令完全由电脑发送，对市场数据的响应延时在微秒级</li>
<li>系统由专门的软硬件组成，研发时需要大量计算机专家级的工作</li>
<li>系统的硬件需要放在离交易所主机很近的位置上，所谓co-location。并且得到专门的准入许可证，交易指令直接发送至交易所。<br>高频，并非指成交的频率高，有些系统只是下委托单和修改、回撤委托单的频率高。高频交易主要包括下面几种类型：</li>
<li>被动做市 这种策略是在交易所挂限价单进行双边交易以提供流动性。所谓双边交易，是指做市商手中持有一定存货，然后同时进行买和卖双方交易。这种策略的买入包括买卖价差和交易所提供的返佣两部分。</li>
<li>套利 就是看两种高相关性的产品之间的价差。</li>
<li>结构化 就是利用技术手段，比如高速连接和下单，来探测其他较慢的市场参与者的交易意图并且抢在他们之前进行交易。将利润建立在他人损失上。</li>
<li>趋势 这个策略本身在低频也存在。简而言之，就是预测一定时间内的价格走势，顺势而为。<h3 id="高频交易的动力：追逐流动性的交易所们"><a href="#高频交易的动力：追逐流动性的交易所们" class="headerlink" title="高频交易的动力：追逐流动性的交易所们"></a>高频交易的动力：追逐流动性的交易所们</h3></li>
<li>高频做市策略的动机和驱动力：在市场碎片化的大背景下，各家交易所为提高自身竞争力从而吸引更多交易量，必须聘请高水平做市商入驻，帮助改善流动性质量。</li>
<li>高频做市商所做交易的行为本质：这种交易只求参与其中，作为买卖双方的中转即可，并不需要追求买卖价差的绝对数值。极端情况下，参与程度本身即为所出售的产品，而具体的某笔交易并不以盈利为目的。<h3 id="高频交易的理论基石：市场微观结构"><a href="#高频交易的理论基石：市场微观结构" class="headerlink" title="高频交易的理论基石：市场微观结构"></a>高频交易的理论基石：市场微观结构</h3>HFT(High Frequency Trading) is the price to pay for fragmentation; it is not possible to put trading venues in competition without agents building high-frequency liquidity bridges across them.</li>
</ul>
<h2 id="高频交易的技术"><a href="#高频交易的技术" class="headerlink" title="高频交易的技术"></a>高频交易的技术</h2><h2 id="高频交易的策略"><a href="#高频交易的策略" class="headerlink" title="高频交易的策略"></a>高频交易的策略</h2><h2 id="高频交易的职业选择"><a href="#高频交易的职业选择" class="headerlink" title="高频交易的职业选择"></a>高频交易的职业选择</h2><h3 id="去基金公司而不是单干"><a href="#去基金公司而不是单干" class="headerlink" title="去基金公司而不是单干"></a>去基金公司而不是单干</h3><ul>
<li>缺钱</li>
<li>杠杆</li>
<li>公司的IT系统支持<h3 id="Quant和程序员差别"><a href="#Quant和程序员差别" class="headerlink" title="Quant和程序员差别"></a>Quant和程序员差别</h3></li>
<li>Quant的工作主要还是和数字打交道，写程序的目的是为了用计算机去解决数字计算的问题。<h3 id="Quant分类：P-Quant和Q-Quant"><a href="#Quant分类：P-Quant和Q-Quant" class="headerlink" title="Quant分类：P Quant和Q Quant"></a>Quant分类：P Quant和Q Quant</h3></li>
<li>Q重模型而轻数据，P重数据而轻模型。<h3 id="如何成为优秀的Quant"><a href="#如何成为优秀的Quant" class="headerlink" title="如何成为优秀的Quant"></a>如何成为优秀的Quant</h3></li>
<li>理解人性</li>
<li>合作</li>
<li>理性</li>
<li>抗压</li>
<li>珍惜亲人</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;高频交易是为了增加市场流动性。&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="知识储备" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/"/>
    
    
      <category term="Book" scheme="http://luxialan.com/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>【人件】 读书笔记</title>
    <link href="http://luxialan.com/2017/02/23/%E3%80%90%E4%BA%BA%E4%BB%B6%E3%80%91-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <id>http://luxialan.com/2017/02/23/【人件】-读书笔记/</id>
    <published>2017-02-23T00:57:08.000Z</published>
    <updated>2017-02-23T02:58:02.000Z</updated>
    
    <content type="html"><![CDATA[<p>人不仅仅是个物件，还有人性。<br><a id="more"></a></p>
<ul>
<li>管理人力资源</li>
<li>舒适的办公环境</li>
<li>合适的员工</li>
<li>高效的团队</li>
<li>工作的趣味</li>
<li>番外</li>
</ul>
<h2 id="管理人力资源"><a href="#管理人力资源" class="headerlink" title="管理人力资源"></a>管理人力资源</h2><ul>
<li>本质上，我们工作中的主要问题，与其说是技术问题，不如说是社会学问题：容许和鼓励犯错；高压管理和限制性措施对于脑力劳动者几乎是多余的；培养和保持员工的独特性</li>
<li>有意义的生产力，人们在收到时间重压的时候不是工作得更好，只是工作得更快：强迫人们加班加点、产品开发工程的机械化、在产品质量上的妥协、生产过程的标准化。</li>
<li>产品的质量，远远超过最终用户需求的质量是一种获得更高生产力的手段。质量是免费的，但是只是对于那些愿意对此付出巨大代价的人而言。</li>
<li>进度估算。不合理和不现实的项目估算会毁掉生产力。</li>
<li>经理的职能不是强迫人们工作，而是让人们有可能工作。</li>
</ul>
<h2 id="办公环境"><a href="#办公环境" class="headerlink" title="办公环境"></a>办公环境</h2><ul>
<li>语言、工作经验、缺陷数量和薪资与绩效的相关性很小或没有相关性。</li>
<li>搭档和工作环境能影响生产力。足够的空间、足够的安宁和足够的方法来确保员工独处而不受干扰，以便人们创造他们自己合理的工作空间。</li>
</ul>
<h2 id="合适的员工"><a href="#合适的员工" class="headerlink" title="合适的员工"></a>合适的员工</h2><ul>
<li>雇佣合适的人</li>
<li>使他们觉得开心，这样他们就不想离开</li>
<li>宽松对待他们</li>
</ul>
<h2 id="高效的团队"><a href="#高效的团队" class="headerlink" title="高效的团队"></a>高效的团队</h2><ul>
<li>挑战性的工作</li>
<li>团队交互作用:一个团队的目的不是达到目标而是向目标看齐；低流动率的团队。</li>
<li>反面例子：防范性管理、官僚作风、物理上的分离、员工的时间分割、产品质量要求较低、假的截止期限、派系控制。</li>
<li>正面例子：质量崇拜、提供许多令人满意的完形、建立精英意识、允许和鼓励异端、保持和保护成功的团队、提供战略但不是战术指导。</li>
</ul>
<h2 id="工作的趣味"><a href="#工作的趣味" class="headerlink" title="工作的趣味"></a>工作的趣味</h2><ul>
<li>混乱与秩序。偶尔引入些许混乱：前导项目、战争游戏、发表独创性意见的自由讨论、煽动性的培训经验、培训、旅游、会议、庆祝会以及休养所。</li>
</ul>
<h2 id="番外"><a href="#番外" class="headerlink" title="番外"></a>番外</h2><ul>
<li>团队建设反例：海报和招贴牌，加班，竞争，年薪或绩效考评，目标管理，褒奖出色完成任务的某些员工，奖励、奖金、红利与绩效挂钩，用几乎任何形式测量绩效。</li>
<li>不要惧怕失败和改变</li>
<li>社区建设</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>个人管理是辅助自己更有效率、更愉快、更有意义地工作，团队管理是辅助员工更有效率、更愉快、更有意义地工作。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://book.douban.com/subject/1108725/" target="_blank" rel="external">人件</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;人不仅仅是个物件，还有人性。&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="知识储备" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/"/>
    
    
      <category term="Book" scheme="http://luxialan.com/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>【深度学习】 读书笔记 柒 深度学习的正则化</title>
    <link href="http://luxialan.com/2017/02/21/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E6%9F%92-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    <id>http://luxialan.com/2017/02/21/【深度学习】-读书笔记-柒-深度学习的正则化/</id>
    <published>2017-02-21T00:44:36.000Z</published>
    <updated>2017-02-23T06:43:54.000Z</updated>
    
    <content type="html"><![CDATA[<p>前馈神经网络对于机器学习的实践是极其重要的。<br><a id="more"></a></p>
<ul>
<li>参数范数惩罚</li>
<li>作为约束的范数惩罚</li>
<li>正则化和欠约束问题</li>
<li>数据集增强</li>
<li>噪声鲁棒性</li>
<li>半监督学习</li>
<li>多人物学习</li>
<li>提前终止</li>
<li>参数绑定与参数共享</li>
<li>稀疏表示</li>
<li>Bagging和其他集成方法</li>
<li>dropout</li>
<li>对抗训练</li>
<li>切面距离、正切传播和流行切分类</li>
</ul>
<p>许多策略被明确设计为以增大训练误差为代价来减少测试误差。这些策略统称为正则化。<br>正则化：为了减少学习算法的泛化误差而不是训练误差的修改。<br>正则化策略：向机器学习模型添加额外的约束，如增加对参数的限制。向目标函数增加额外项，对应于参数值的软约束<br>正则化的设计：编码特定类型的先验知识；表达对简单模型的一般偏好；确定欠定的问题；结合多个假说来训练数据。<br>要侧重模型族训练的情形：</p>
<ul>
<li>（1）不包括真实的数据生成过程————对应于欠拟合和偏差引入</li>
<li>（2）匹配真实数据生成过程</li>
<li>（3）除了包含真是的数据生成过程，还包含了许多其他可能的生成过程————方差（而不是偏差）主导的过拟合<br>正则化的目标是使模型从第三种情况进入到第二种情况。</li>
</ul>
<h2 id="参数范数惩罚"><a href="#参数范数惩罚" class="headerlink" title="参数范数惩罚"></a>参数范数惩罚</h2><p>正则化后的目标函数$$\hat(J)(\theta;X,y)=J(\theta;X,y)+\alpha\Omega(\theta)$$<br>其中$\alpha\in[0,\infty$)是权衡范数惩罚项$\Omega$和标准目标函数$J(X;\theta)$相对贡献的超参数。</p>
<h3 id="L-2-参数正则化"><a href="#L-2-参数正则化" class="headerlink" title="$L^{2}$参数正则化"></a>$L^{2}$参数正则化</h3><p>$L^2$参数衰减<br>权重衰减$L^2$参数范数惩罚$\Omega(\theta)=frac{1}{2}||w||^{2}_{2}$使得权重更加接近原点。在其他学术圈，$L^2$也被称为岭回归或$Tikhonov$正则。</p>
<h2 id="作为约束的范数惩罚"><a href="#作为约束的范数惩罚" class="headerlink" title="作为约束的范数惩罚"></a>作为约束的范数惩罚</h2><p>考虑通过参数范数正则化的代价函数：<br>$$\hat(J)(\theta;X,y)=J(\theta;X,y)+\alpha\Omega(\theta)$$</p>
<h2 id="正则化和欠约束问题"><a href="#正则化和欠约束问题" class="headerlink" title="正则化和欠约束问题"></a>正则化和欠约束问题</h2><p>正则化的许多形式对应于求逆$X^{T}X+\alpha I$.这个正则化矩阵是可以保证是可逆的。<br>大多数形式的正则化能够保证应用于欠定问题的迭代方法收敛。例如，当似然的斜率等于权重衰减的系数时，权重衰减将导致梯度下降不再增加权重的大小。<br>使用正则化来坚决欠定问题。</p>
<h2 id="数据集增强"><a href="#数据集增强" class="headerlink" title="数据集增强"></a>数据集增强</h2><h2 id="噪声鲁棒性"><a href="#噪声鲁棒性" class="headerlink" title="噪声鲁棒性"></a>噪声鲁棒性</h2><p>模型的输入加上方差极小的噪音等价于对权重施加范数惩罚。在一般情况下，噪声注入远远比简单地收缩参数强大，特别是噪声被添加到隐藏单元时。向隐藏单元添加噪音是值得单独讨论重要的话题。在第7.12节所述$dropout$算法这种做法主要发展方向。<br>循环神经网络的情况下，权重的贝叶斯推断的随机实现。使用贝叶斯处理学习过程将</p>
<h2 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h2><p>长期存在的一个变种是应用主成分分析作为分类前（在投影后的数据上分类）的预处理步骤。</p>
<h2 id="多任务学习"><a href="#多任务学习" class="headerlink" title="多任务学习"></a>多任务学习</h2><p>合并几个任务中的样例（可以视为对参数施加的软约束）来提高泛化的一种方式。额外的训练样本以同样的方式将模型的参数推向泛化更好的方向。<br>仅当不同的任务之间存在某些统计关系的假设是合理时才会发生。</p>
<h2 id="提前终止"><a href="#提前终止" class="headerlink" title="提前终止"></a>提前终止</h2><p>这意味着我们可以返回使验证集误差最低的参数设置来获得更好的模型。这可能是深度学习中最常用的正则化形式。</p>
<h2 id="参数绑定和参数共享"><a href="#参数绑定和参数共享" class="headerlink" title="参数绑定和参数共享"></a>参数绑定和参数共享</h2><p>表达我们对模型参数适当值得先验知识。<br>经常想要表达的常见类型的依赖是某些参数应当彼此接近。</p>
<h2 id="稀疏表示"><a href="#稀疏表示" class="headerlink" title="稀疏表示"></a>稀疏表示</h2><p>$L^{1}$惩罚如何诱导稀疏的参数，意味着许多参数为零（或接近于零）。</p>
<h2 id="Bagging和其他集成的方法"><a href="#Bagging和其他集成的方法" class="headerlink" title="Bagging和其他集成的方法"></a>Bagging和其他集成的方法</h2><p>$Bagging(bootstrap aggregating)$是通过结合几个模型降低泛化误差的技术。<br>模型平均(model averaging)奏效的原因是不同的模型通常不会再测试集上产生完全相同的错误。<br>具体来说，Bagging涉及构造$k$个不同的数据集。每个数据集与原始数据集具有相同数量的样例，但从原始数据集中有替换采样构成。</p>
<h2 id="dropout"><a href="#dropout" class="headerlink" title="dropout"></a>dropout</h2><p>$dropout$提供了正则化一大类模型的方法，计算方便但功能强大。$dropout$可以被认为是集成非常多的大神经网络的实用$Bagging$方法。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/exacity/deeplearningbook-chinese" target="_blank" rel="external">Deep Learning Book</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前馈神经网络对于机器学习的实践是极其重要的。&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="知识储备" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/"/>
    
    
      <category term="Book" scheme="http://luxialan.com/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>【深度学习】 读书笔记 陆 深度前馈网络</title>
    <link href="http://luxialan.com/2017/02/18/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E9%99%86-%E6%B7%B1%E5%BA%A6%E5%89%8D%E9%A6%88%E7%BD%91%E7%BB%9C/"/>
    <id>http://luxialan.com/2017/02/18/【深度学习】-读书笔记-陆-深度前馈网络/</id>
    <published>2017-02-18T07:52:57.000Z</published>
    <updated>2017-02-23T06:43:02.000Z</updated>
    
    <content type="html"><![CDATA[<p>深度学习的基础网络<br><a id="more"></a></p>
<ul>
<li>实例: 学习XOR</li>
</ul>
<p>深度前馈网络(deep feedforward network)\前馈神经网络(feedforward neural network)\多层感知机(multilayer perception,MLP)<br>前馈网络的目标是近似某个函数$f^{*}$<br>前向，是因为信息流过$x$的函数，流过用于定义$f$的中间计算过程，最终到达输出$y$。即$x-&gt;f-&gt;y$<br>网络，是因为他们通常用许多不同函数复合在一起，例如$f(x)=f^{(3)}(f^{(2)}(f^{(3)}))$。</p>
<p>线性模型是非常吸引人的，因为高效而可靠地适用在无论是封闭形式还是凸优化里。线性模型也有明显的缺陷，那就是该模型的能力被局限在线性函数里，所以它无法理解任何两个输入变量间的相互作用。<br>核技巧来实现一个本来是基于$\phi$映射的非线性学习算法。我们认为$\phi$提供了一组描述$x$的特征，或者认为它提供了$x$的一个新的表示。<br>如何选择映射$\phi$</p>
<ul>
<li>通用的$\phi$，例如无限维的$\phi$，它隐含地用在基于RBF核的核机器上。如果$\phi(x)$具有足够高的维数，我们总是有足够的能力来适应训练集，但是对于测试集的泛化往往不佳。非常通用的特征映射通常只基于局部平滑的原则，并没有将足够的先验信息进行编码来解决高级的问题。</li>
<li>手动的$\phi$</li>
<li>深度学习的策略是去学习$\phi$。在这种方法中，我们有一个模型$y=f(x;\theta,w)=\phi(x;\theta)^{T}w$。<br>通过学习特征来改善模型的一般化原则不止适用于本章描述的前馈神经网络。它是深度学习中反复出现的主题，适用于全书描述的所有种类的模型。</li>
</ul>
<h2 id="实例：学习XOR"><a href="#实例：学习XOR" class="headerlink" title="实例：学习XOR"></a>实例：学习XOR</h2><h2 id="基于梯度的学习"><a href="#基于梯度的学习" class="headerlink" title="基于梯度的学习"></a>基于梯度的学习</h2><p>线性模型和神经网络的最大区别，在于神经网络的非线性导致大多数我们感兴趣的损失函数都成为了非凸的。</p>
<h3 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h3><h3 id="用最大似然学习条件分布"><a href="#用最大似然学习条件分布" class="headerlink" title="用最大似然学习条件分布"></a>用最大似然学习条件分布</h3><p>### </p>
<p>### </p>
<p>### </p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;深度学习的基础网络&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="知识储备" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/"/>
    
    
      <category term="Book" scheme="http://luxialan.com/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>【概率论与数理统计】 读书笔记</title>
    <link href="http://luxialan.com/2017/02/16/%E3%80%90%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E3%80%91-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    <id>http://luxialan.com/2017/02/16/【概率论与数理统计】-读书笔记/</id>
    <published>2017-02-16T06:34:39.000Z</published>
    <updated>2017-02-16T06:38:22.000Z</updated>
    
    <content type="html"><![CDATA[<p>概率论与数理统计基础知识总结<br><a id="more"></a></p>
<ul>
<li>第一章 随机事件与概率</li>
<li>第二章 随机变量及其分布</li>
<li>第三章 多维随机变量及其分布</li>
<li>第四章 大数定律与中心极限定理</li>
<li>第五章 统计量及其分布</li>
<li>第六章 参数估计</li>
<li>第七章 假设检验</li>
<li>第八章 方差分析与回归分析</li>
</ul>
<h3 id="第一章-随机事件与概率"><a href="#第一章-随机事件与概率" class="headerlink" title="第一章 随机事件与概率"></a>第一章 随机事件与概率</h3><h4 id="1-1-随机事件及其运算"><a href="#1-1-随机事件及其运算" class="headerlink" title="1.1 随机事件及其运算"></a>1.1 随机事件及其运算</h4><p>概率论与数理统计研究的对象是随机现象. 概率论是研究随机现象的模型（即概率分布），数理统计是研究随机现象的数据收集与处理。</p>
<ul>
<li>随机现象： 在一定的条件下，并不总是出现相同结果的现象称为随机现象</li>
<li>样本空间：随机现象的一切可能基本结果组成的集合称为样本空间</li>
<li>随机事件：随机现象的某些样本点组成的集合称为随机事件</li>
<li>随机变量：用来表示随机现象结果的变量称为随机变量</li>
<li>事件间的关系：包含，相等，互不相容</li>
<li>事件的运算：并、交、差、对立</li>
<li>事件的运算性质：交换律、结合律、分配律、对偶律</li>
<li>事件域</li>
</ul>
<h4 id="1-2-概率的定义及其确定方法"><a href="#1-2-概率的定义及其确定方法" class="headerlink" title="1.2 概率的定义及其确定方法"></a>1.2 概率的定义及其确定方法</h4><h5 id="概率的公理化定义"><a href="#概率的公理化定义" class="headerlink" title="概率的公理化定义"></a>概率的公理化定义</h5><ul>
<li>非负性公理</li>
<li>正则性公理</li>
<li>可列可加性公理<h5 id="排列与组合性质"><a href="#排列与组合性质" class="headerlink" title="排列与组合性质"></a>排列与组合性质</h5></li>
<li>乘法原理</li>
<li>加法原理<h5 id="排列与组合公式"><a href="#排列与组合公式" class="headerlink" title="排列与组合公式"></a>排列与组合公式</h5></li>
<li>排列 P(r,n) </li>
<li>重复排列 n^r</li>
<li>组合 C(r,n) </li>
<li>重复组合 C(r, n+r-1)<h5 id="确定概率的两种方法"><a href="#确定概率的两种方法" class="headerlink" title="确定概率的两种方法"></a>确定概率的两种方法</h5></li>
<li>确定概率的频率方法</li>
<li>确定概率的古典方法</li>
</ul>
<h4 id="1-3概率的性质"><a href="#1-3概率的性质" class="headerlink" title="1.3概率的性质"></a>1.3概率的性质</h4><ul>
<li>概率的可加性</li>
<li>概率的单调性</li>
<li>概率的加法公式</li>
<li>概率的连续性</li>
</ul>
<h4 id="1-4条件概率"><a href="#1-4条件概率" class="headerlink" title="1.4条件概率"></a>1.4条件概率</h4><ul>
<li>乘法公式</li>
<li>全概率公式</li>
<li>贝叶斯公式</li>
</ul>
<h4 id="1-5独立性"><a href="#1-5独立性" class="headerlink" title="1.5独立性"></a>1.5独立性</h4><p>一个事件的发生不影响另一个事件的发生</p>
<h3 id="第二章-随机变量及其分布"><a href="#第二章-随机变量及其分布" class="headerlink" title="第二章 随机变量及其分布"></a>第二章 随机变量及其分布</h3><h4 id="2-1-随机变量及其分布"><a href="#2-1-随机变量及其分布" class="headerlink" title="2.1 随机变量及其分布"></a>2.1 随机变量及其分布</h4><h5 id="随机变量的分布函数"><a href="#随机变量的分布函数" class="headerlink" title="随机变量的分布函数"></a>随机变量的分布函数</h5><ul>
<li>单调性</li>
<li>有界性</li>
<li>右连续性</li>
</ul>
<h5 id="离散随机变量的概率分布列"><a href="#离散随机变量的概率分布列" class="headerlink" title="离散随机变量的概率分布列"></a>离散随机变量的概率分布列</h5><p>分布列的基本性质</p>
<ul>
<li>非负性</li>
<li>正则性</li>
</ul>
<h4 id="2-2-随机变量的数学期望"><a href="#2-2-随机变量的数学期望" class="headerlink" title="2.2 随机变量的数学期望"></a>2.2 随机变量的数学期望</h4><p>数学期望的性质</p>
<h4 id="2-3-随机变量的方差与标准差"><a href="#2-3-随机变量的方差与标准差" class="headerlink" title="2.3 随机变量的方差与标准差"></a>2.3 随机变量的方差与标准差</h4><ul>
<li>切比雪夫不等式 </li>
</ul>
<h4 id="2-4常用离散分布"><a href="#2-4常用离散分布" class="headerlink" title="2.4常用离散分布"></a>2.4常用离散分布</h4><ul>
<li>二项分布</li>
<li>二点分布</li>
<li>泊松分布</li>
<li>超几何分布</li>
<li>几何分布</li>
</ul>
<h4 id="2-5常用连续分布"><a href="#2-5常用连续分布" class="headerlink" title="2.5常用连续分布"></a>2.5常用连续分布</h4><ul>
<li>正态分布</li>
<li>均匀分布</li>
<li>指数分布</li>
<li>伽马分布</li>
<li>贝塔分布</li>
</ul>
<h4 id="2-6-随机变量函数的分布"><a href="#2-6-随机变量函数的分布" class="headerlink" title="2.6 随机变量函数的分布"></a>2.6 随机变量函数的分布</h4><h4 id="2-7-分布的其他特征数"><a href="#2-7-分布的其他特征数" class="headerlink" title="2.7 分布的其他特征数"></a>2.7 分布的其他特征数</h4><ul>
<li>k阶矩</li>
<li>k阶原点矩</li>
<li>k阶中心矩</li>
<li>变异系数</li>
<li>分位数</li>
<li>中位数</li>
<li>偏度系数</li>
<li>峰度系数</li>
</ul>
<h3 id="第三章-多维随机变量及其分布"><a href="#第三章-多维随机变量及其分布" class="headerlink" title="第三章 多维随机变量及其分布"></a>第三章 多维随机变量及其分布</h3><h4 id="3-1-多维随机变量及其联合分布"><a href="#3-1-多维随机变量及其联合分布" class="headerlink" title="3.1 多维随机变量及其联合分布"></a>3.1 多维随机变量及其联合分布</h4><h5 id="多维随机变量"><a href="#多维随机变量" class="headerlink" title="多维随机变量"></a>多维随机变量</h5><ul>
<li>联合分布函数</li>
<li>联合分布列</li>
<li>联合密度函数<h5 id="多项分布"><a href="#多项分布" class="headerlink" title="多项分布"></a>多项分布</h5></li>
<li>多维超几何分布</li>
<li>多维均匀分布</li>
<li>二元正态分布</li>
</ul>
<h4 id="3-2-边际分布与随机变量的独立性"><a href="#3-2-边际分布与随机变量的独立性" class="headerlink" title="3.2 边际分布与随机变量的独立性"></a>3.2 边际分布与随机变量的独立性</h4><h5 id="多维随机变量函数的分布"><a href="#多维随机变量函数的分布" class="headerlink" title="多维随机变量函数的分布"></a>多维随机变量函数的分布</h5><h5 id="多维随机变量的特征数"><a href="#多维随机变量的特征数" class="headerlink" title="多维随机变量的特征数"></a>多维随机变量的特征数</h5><h5 id="条件分布与条件期望"><a href="#条件分布与条件期望" class="headerlink" title="条件分布与条件期望"></a>条件分布与条件期望</h5><h3 id="第四章-大数定律与中心极限定理"><a href="#第四章-大数定律与中心极限定理" class="headerlink" title="第四章 大数定律与中心极限定理"></a>第四章 大数定律与中心极限定理</h3><h4 id="4-1-随机变量序列的两种收敛性"><a href="#4-1-随机变量序列的两种收敛性" class="headerlink" title="4.1 随机变量序列的两种收敛性"></a>4.1 随机变量序列的两种收敛性</h4><h3 id="第五章-统计量及其分布"><a href="#第五章-统计量及其分布" class="headerlink" title="第五章 统计量及其分布"></a>第五章 统计量及其分布</h3><h4 id="5-1-总体与样本"><a href="#5-1-总体与样本" class="headerlink" title="5.1 总体与样本"></a>5.1 总体与样本</h4><h3 id="第六章-参数估计"><a href="#第六章-参数估计" class="headerlink" title="第六章 参数估计"></a>第六章 参数估计</h3><h4 id="6-1-点估计的概念与无偏性"><a href="#6-1-点估计的概念与无偏性" class="headerlink" title="6.1 点估计的概念与无偏性"></a>6.1 点估计的概念与无偏性</h4><h4 id="6-2-矩估计及相合性"><a href="#6-2-矩估计及相合性" class="headerlink" title="6.2 矩估计及相合性"></a>6.2 矩估计及相合性</h4><h4 id="6-3-最大似然估计与EM算法"><a href="#6-3-最大似然估计与EM算法" class="headerlink" title="6.3 最大似然估计与EM算法"></a>6.3 最大似然估计与EM算法</h4><h4 id="6-4-最小方差无偏估计"><a href="#6-4-最小方差无偏估计" class="headerlink" title="6.4 最小方差无偏估计"></a>6.4 最小方差无偏估计</h4><h4 id="6-5-贝叶斯估计"><a href="#6-5-贝叶斯估计" class="headerlink" title="6.5 贝叶斯估计"></a>6.5 贝叶斯估计</h4><h4 id="6-6-区间估计"><a href="#6-6-区间估计" class="headerlink" title="6.6 区间估计"></a>6.6 区间估计</h4><h3 id="第七章-假设检验"><a href="#第七章-假设检验" class="headerlink" title="第七章 假设检验"></a>第七章 假设检验</h3><h4 id="7-1-假设检验的基本思想和概念"><a href="#7-1-假设检验的基本思想和概念" class="headerlink" title="7.1 假设检验的基本思想和概念"></a>7.1 假设检验的基本思想和概念</h4><h4 id="7-2-正态总体参数假设检验"><a href="#7-2-正态总体参数假设检验" class="headerlink" title="7.2 正态总体参数假设检验"></a>7.2 正态总体参数假设检验</h4><h4 id="7-3-其他分布参数的假设检验"><a href="#7-3-其他分布参数的假设检验" class="headerlink" title="7.3 其他分布参数的假设检验"></a>7.3 其他分布参数的假设检验</h4><h4 id="7-4-似然比检验与分布拟合检验"><a href="#7-4-似然比检验与分布拟合检验" class="headerlink" title="7.4 似然比检验与分布拟合检验"></a>7.4 似然比检验与分布拟合检验</h4><h4 id="7-5-正态性检验"><a href="#7-5-正态性检验" class="headerlink" title="7.5 正态性检验"></a>7.5 正态性检验</h4><h4 id="7-6-非参数检验"><a href="#7-6-非参数检验" class="headerlink" title="7.6 非参数检验"></a>7.6 非参数检验</h4><h3 id="第八章-方差分析与回归分析"><a href="#第八章-方差分析与回归分析" class="headerlink" title="第八章 方差分析与回归分析"></a>第八章 方差分析与回归分析</h3><h4 id="8-1-方差分析"><a href="#8-1-方差分析" class="headerlink" title="8.1 方差分析"></a>8.1 方差分析</h4><h4 id="8-2-多重比较"><a href="#8-2-多重比较" class="headerlink" title="8.2 多重比较"></a>8.2 多重比较</h4><h4 id="8-3-方差齐性检验"><a href="#8-3-方差齐性检验" class="headerlink" title="8.3 方差齐性检验"></a>8.3 方差齐性检验</h4><h4 id="8-4-一元线性回归"><a href="#8-4-一元线性回归" class="headerlink" title="8.4 一元线性回归"></a>8.4 一元线性回归</h4><h4 id="8-5-一元非线性回归"><a href="#8-5-一元非线性回归" class="headerlink" title="8.5 一元非线性回归"></a>8.5 一元非线性回归</h4>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;概率论与数理统计基础知识总结&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="知识储备" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/"/>
    
    
      <category term="Book" scheme="http://luxialan.com/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>理财基础指南</title>
    <link href="http://luxialan.com/2017/02/15/%E7%90%86%E8%B4%A2%E5%9F%BA%E7%A1%80%E6%8C%87%E5%8D%97/"/>
    <id>http://luxialan.com/2017/02/15/理财基础指南/</id>
    <published>2017-02-15T08:37:54.000Z</published>
    <updated>2017-02-16T06:47:32.000Z</updated>
    
    <content type="html"><![CDATA[<p>你不理财，财不理你<br><a id="more"></a><br>投资渠道</p>
<ul>
<li>基金定投</li>
<li>银行储蓄</li>
<li>余额宝类产品</li>
<li>P2P网贷</li>
</ul>
<h3 id="基金："><a href="#基金：" class="headerlink" title="基金："></a>基金：</h3><h4 id="基金分红"><a href="#基金分红" class="headerlink" title="基金分红:"></a>基金分红:</h4><p>现金分红、红利再投资。</p>
<h4 id="货币基金："><a href="#货币基金：" class="headerlink" title="货币基金："></a>货币基金：</h4><p>基金资产全部投资于短期货币市场工具，比如银行大额存单等无风险或者低风险的资产。</p>
<h4 id="债券基金："><a href="#债券基金：" class="headerlink" title="债券基金："></a>债券基金：</h4><p>基金资产80%以上投资于各类债券，比如企业债券、金融债券等。债券型基金又分为纯债型基金和偏债型基金(或者称为二级债基)。<br>纯债基金:资产=债券+银行存款，风险收益低，一般在5%-10%左右；<br>二级债基:资产=债券+银行存款+不超过20%的股票。风险适中，收益比纯债基好，一般在10%-20%之间。</p>
<h4 id="股票型基金："><a href="#股票型基金：" class="headerlink" title="股票型基金："></a>股票型基金：</h4><p>资产中80%以上投资于股票。风险大，收益高，15%以上的年化收益问题不大。</p>
<h4 id="混合型基金："><a href="#混合型基金：" class="headerlink" title="混合型基金："></a>混合型基金：</h4><p>资产=股票+债券+货币市场工具。股票和债券投资比例灵活。收益在股票基金和债券基金之间。</p>
<h4 id="指数型基金："><a href="#指数型基金：" class="headerlink" title="指数型基金："></a>指数型基金：</h4><p>仅投资标的指数的成份股，对指数进行复制。<br>指数基金的目的不是为了获得超越市场的收益，而是让这个投资组合的波动与该指数一致，取得与指数大致相同的收益率。<br>四大常见指数</p>
<ul>
<li>沪深300：这是个跨市场的指数，是从上海和深圳证券市场中选取300只规模大、流动性好的300只股票作为样本；覆盖了沪深市场60%左右的市值，具有良好的市场代表性。</li>
<li>中证500：扣除沪深300指数样本、按日均总市值高低排名选取前500名股票作为样本，综合反映沪深证券市场内小市值公司的整体状况；是一只综合体现沪深两市小市值企业的指数，是期望分享高成长收益投资者的最佳选择。</li>
<li>上证50: 挑选上海证券市场规模大、流动性好的最具代表性的50只股票组成样本股，综合反映上海证券市场最具市场影响力的一批龙头企业的整体状况；是优质蓝筹股的突触代表。</li>
<li>中证100：从沪深300指数样本股中挑选规模最大的100只股票组成样本股，以综合反映沪深证券市场中最具市场影响力的一批大市值公司的整体状况。</li>
</ul>
<h4 id="基金价值的衡量：基金的净值代表一份基金值多少钱。但是对于投资者而言，应该关心基金未来的净值。"><a href="#基金价值的衡量：基金的净值代表一份基金值多少钱。但是对于投资者而言，应该关心基金未来的净值。" class="headerlink" title="基金价值的衡量：基金的净值代表一份基金值多少钱。但是对于投资者而言，应该关心基金未来的净值。"></a>基金价值的衡量：基金的净值代表一份基金值多少钱。但是对于投资者而言，应该关心基金未来的净值。</h4><h2 id="个人总结"><a href="#个人总结" class="headerlink" title="个人总结"></a>个人总结</h2><p>理财重要的核心</p>
<ul>
<li>复利，滴水石穿，积少成多</li>
<li>预期，比现在更重要的是未来</li>
<li>价值，价格会波动，但是最终会回归价值</li>
<li>投资与保值，资产不是一个固定的概念，而是一个流动的概念，即使不是为赚钱投资，为了资产不贬值，也需要对资产进行不同形式的配置。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;你不理财，财不理你&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="经济金融" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%BB%8F%E6%B5%8E%E9%87%91%E8%9E%8D/"/>
    
    
      <category term="Economy/Finance" scheme="http://luxialan.com/tags/Economy-Finance/"/>
    
  </entry>
  
  <entry>
    <title>【深度学习】 读书笔记 伍 机器学习基础</title>
    <link href="http://luxialan.com/2017/02/14/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E4%BC%8D-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    <id>http://luxialan.com/2017/02/14/【深度学习】-读书笔记-伍-机器学习基础/</id>
    <published>2017-02-14T06:38:12.000Z</published>
    <updated>2017-02-16T06:51:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>机器学习本质上属于应用统计学，更多关注于如何用计算机统计地估计复杂函数，不太关注这些函数的置信区间。<br><a id="more"></a></p>
<ul>
<li>1.学习算法</li>
<li>2.容量、过拟合和欠拟合</li>
<li>3.超参数和验证集</li>
<li>4.估计、偏差和方差</li>
<li>5.最大似然估计</li>
<li>6.贝叶斯统计</li>
<li>7.监督学习方法</li>
<li>8.无监督学习方法</li>
<li>9.随机梯度下降</li>
<li>10.构建机器学习算法</li>
<li>11.推动机深度学习的挑战</li>
</ul>
<h2 id="学习算法"><a href="#学习算法" class="headerlink" title="学习算法"></a>学习算法</h2><p>对于某类任务$T$和性能度量$P$,一个计算机程序被认为可以从经验$E$中学习是指，通过经验E改进后，它在任务$T$上由性能度量$P$衡量的性能有所提升。</p>
<h3 id="任务"><a href="#任务" class="headerlink" title="任务"></a>任务</h3><ul>
<li>分类</li>
<li>输入缺失分类</li>
<li>回归</li>
<li>转录</li>
<li>机器翻译</li>
<li>结构化输出</li>
<li>异常检测</li>
<li>合成和采样</li>
<li>缺失值填补</li>
<li>去噪</li>
<li>密度估计或概率分布律函数估计</li>
</ul>
<h3 id="性能度量，-P"><a href="#性能度量，-P" class="headerlink" title="性能度量，$P$"></a>性能度量，$P$</h3><ul>
<li>准确率</li>
<li>错误率</li>
<li>测试集</li>
</ul>
<h3 id="经验"><a href="#经验" class="headerlink" title="经验"></a>经验</h3><ul>
<li>无监督学习算法</li>
<li>有监督学习算法</li>
</ul>
<h3 id="实例-线性回归"><a href="#实例-线性回归" class="headerlink" title="实例:线性回归"></a>实例:线性回归</h3><p>目标是建立一个系统，将向量$x\in\mathbb{R}^n$作为输入，预测标量$y\in \mathbb{R}$作为输出。线性回归的输出是其输入的线性函数。</p>
<h2 id="容量，过拟合和欠拟合"><a href="#容量，过拟合和欠拟合" class="headerlink" title="容量，过拟合和欠拟合"></a>容量，过拟合和欠拟合</h2><h3 id="泛化"><a href="#泛化" class="headerlink" title="泛化"></a>泛化</h3><p>在未观测到的输入上表现良好的能力被称为泛化(generalization).</p>
<h3 id="性能的测量"><a href="#性能的测量" class="headerlink" title="性能的测量"></a>性能的测量</h3><p>训练误差，泛化误差\测试误差</p>
<h3 id="独立同分布假设"><a href="#独立同分布假设" class="headerlink" title="独立同分布假设"></a>独立同分布假设</h3><p>该假设是说，每个数据集中的样本都是彼此相互独立的，并且训练集和测试集是同分布的，其上数据采样自相同的分布。这个假设使我们能够在单个样本上用概率分布描述数据生成过程。然后相同的分布可以用来生成每一个训练样本和每一个测试样本。<br>测试误差期望会大于或等于训练误差期望。以下是决定机器学习算法效果是否好的因素：</p>
<ul>
<li>降低训练误差</li>
<li>缩小训练误差和测试误差的差距<br>这两个因素对应机器学习的两个主要挑战。</li>
<li>欠拟合。欠拟合发生在模型不能再训练集上获得足够的误差。</li>
<li>过拟合。过拟合发生在训练误差和测试误差之间的差距过大。</li>
</ul>
<h3 id="容量"><a href="#容量" class="headerlink" title="容量"></a>容量</h3><p>模型的容量是指其拟合各种函数的能力。容量低的模型可能很难拟合训练集。容量高的模型可能会过拟合，因为记住了不适用于测试集的训练集性质。</p>
<h3 id="控制容量"><a href="#控制容量" class="headerlink" title="控制容量"></a>控制容量</h3><p>一种控制训练算法容量的方法是选择假设空间，即能够选为解决方案的学习算法函数集。例如，线性回归函数将关于其输入的所有线性函数作为假设空间。广义线性回归的假设空间包括多项式函数，而非仅有线性函数。</p>
<h3 id="奥卡姆剃刀-Occam’s-razor"><a href="#奥卡姆剃刀-Occam’s-razor" class="headerlink" title="奥卡姆剃刀(Occam’s razor)"></a>奥卡姆剃刀(Occam’s razor)</h3><p>统计学习理论提供了量化模型容量的不同方法。在这些中，最有名的是${Vapnik-Chervonenkis}$维度。VC维定义为该分类器能够分类的训练样本的最大数目。</p>
<h3 id="没有免费午餐定理。"><a href="#没有免费午餐定理。" class="headerlink" title="没有免费午餐定理。"></a>没有免费午餐定理。</h3><p>在所有可能的数据生成分布上平均，每一个分类算法在未事先观测的点上都有相同的错误率。换言之，在某种意义上，没有一个机器学习算法总是比其他的要好。<br>幸运的是，这些结论仅在我们考虑所有可能的数据生成分布时才成立。对遇到的概率分布进行假设的话，那么我们可以设计在这些分布上效果良好的学习算法。这意味着机器学习研究的目标不是找一个通用学习算法或是绝对最好的学习算法。我们的目标是理解什么样的分布和人工智能获取经验的“真实世界”相关，什么样的学习算法在我们关注的数据生成分布上效果最好。</p>
<h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><p>没有免费午餐定理暗示我们必须在特定任务上设计性能良好的机器学习算法。当这些偏好和我们希望算法解决的学习问题相吻合时，性能会更好。<br>算法的效果不仅受影响于假设空间的函数数量，也取决于这些函数的具体形式。可以通过控制允许采样的函数种类的方式，也可以通过控制这些函数的数量的方式。</p>
<h2 id="超参数和验证集"><a href="#超参数和验证集" class="headerlink" title="超参数和验证集"></a>超参数和验证集</h2><h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><p>在原始数据上随机采样或分离出的不同数据集上重复训练和测试的想法。最常见的是$k$-折交叉验证过程：</p>
<ul>
<li>将数据集分成k个不重合的子集。测试误差可以估计为$k$次计算后的平均测试误差。在第$i$次测试时，数据的第$i$个子集用于测试集，其他的数据用于训练集。</li>
</ul>
<h2 id="估计，偏差和方差"><a href="#估计，偏差和方差" class="headerlink" title="估计，偏差和方差"></a>估计，偏差和方差</h2><p>统计领域为我们提供了很多工具用于实现机器学习目标，不仅可以解决训练集上的任务，还可以泛化。基本的概念，例如参数估计，偏差和方差，对于形式化刻画泛化，欠拟合和过拟合都非常有帮助。</p>
<h3 id="点估计"><a href="#点估计" class="headerlink" title="点估计"></a>点估计</h3><p>点估计试图为一些感兴趣的量提供单个“最优”预测。一般地，感兴趣的量可以是单个参数，或是某些参数模型中的一个向量参数。<br>为了区分参数估计和真实值，我们习惯表示参数$\theta$的点估计为$\hat{\theta}$<br>让${x^{1},…,x^{m}}$是m个独立同分布的数据点。点估计或统计量是这些数据的任意函数：<br>$$\hat{\theta_m}=g(x^{(1)},…,x^{(m)})$$<br>一个好的估计量的输出会接近生成训练数据的真实参数$/theta$。<br>点估计也可以指输入和目标变量之间关系的估计。我们将这类点估计称为函数估计。</p>
<h3 id="偏差"><a href="#偏差" class="headerlink" title="偏差"></a>偏差</h3><p>估计的偏差：$bias(\hat{\theta_m})=\mathbb{E}(\hat{\theta_m})-\theta$<br>无偏：$\mathbb{E}(\hat{\theta<em>m})=\theta$<br>渐近无偏：$lim</em>{m-\mapsto\infty}\mathbb{E}(\hat{\theta_m})=\theta$</p>
<h3 id="方差和标准误差"><a href="#方差和标准误差" class="headerlink" title="方差和标准误差"></a>方差和标准误差</h3><p>数据样本函数的变化程度。计算估计量的期望来决定他的偏差。<br>估计量的方差</p>
<h2 id="监督学习算法"><a href="#监督学习算法" class="headerlink" title="监督学习算法"></a>监督学习算法</h2><h3 id="概率监督学习"><a href="#概率监督学习" class="headerlink" title="概率监督学习"></a>概率监督学习</h3><p>本书的大部分监督学习算法都是基于估计概率分布$p(y|x)$。我们可以使用最大似然估计找到对于有参分布族$p(y|x,\theta)$最好的参数向量$\theta$<br>$$p(y|x,\theta)=N(y;\theta^{T}x,I)$$<br>logistic sigmoid函数将线性函数的输出压缩进区间(0,1)。该值可以解释为概率：$$p(y=1|x;\theta)=\sigma(\theta^{T}x)$$<br>最大化对数似然来搜索最优解。</p>
<h3 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h3><p>支持向量机模型：支持向量机不输出概率，只输出类别。当$w^{T}x+b$为正时，支持向量机预测属于正类。类似地，当当$w^{T}x+b$为负时，支持向量机预测属于负类。<br>支持向量机的一个重要创新是核技巧。<br>核技巧十分强大有两大原因：</p>
<ul>
<li>使我们能够使用保证有效收敛的凸优化技术来学习作为$x$的函数的非线性模型。即优化算法可以将决策函数视为不同空间中的线性函数。</li>
<li>核函数k的实现方法通常有比直接构建$\theta(x)$再算点积高效很多。<br>最常用的核函数是高斯核</li>
</ul>
<h3 id="其他简单的监督学习算法"><a href="#其他简单的监督学习算法" class="headerlink" title="其他简单的监督学习算法"></a>其他简单的监督学习算法</h3><p>k-近邻、决策树</p>
<h2 id="无监督学习算法"><a href="#无监督学习算法" class="headerlink" title="无监督学习算法"></a>无监督学习算法</h2><p>无监督学习是指从不需要人为注释样本的分布中抽取信息的大多数尝试。该术语通常与密度估计相关，学习从分布中采样，学习从分布中去噪，需要数据分布的流形，或是将数据中相关的样本聚类。一个经典的无监督学习任务是找到数据的“最佳”表示。</p>
<ul>
<li>低维表示：尝试将x中的信息尽可能压缩在一个较小的表示中。</li>
<li>稀疏表示：通常用于需要增加表示维数的情况，使得大部分为零的表示不会丢失很多信息。这会使得表示的整体结构倾向于将数据分布在表示空间的坐标轴上。</li>
<li>独立表示：试图解开数据分布中变动的来源，使得表示的维度是统计独立的。</li>
</ul>
<h3 id="主成分分析"><a href="#主成分分析" class="headerlink" title="主成分分析"></a>主成分分析</h3><h3 id="k-均值聚类"><a href="#k-均值聚类" class="headerlink" title="k-均值聚类"></a>k-均值聚类</h3><h2 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a>随机梯度下降</h2><h2 id="构建机器学习算法"><a href="#构建机器学习算法" class="headerlink" title="构建机器学习算法"></a>构建机器学习算法</h2><h2 id="推动深度学习的挑战"><a href="#推动深度学习的挑战" class="headerlink" title="推动深度学习的挑战"></a>推动深度学习的挑战</h2><h3 id="维度灾难"><a href="#维度灾难" class="headerlink" title="维度灾难"></a>维度灾难</h3><p>一组变量的不同可能配置数量随着变量数目的增加而指数级增长。</p>
<h3 id="局部不变性和平滑正则化"><a href="#局部不变性和平滑正则化" class="headerlink" title="局部不变性和平滑正则化"></a>局部不变性和平滑正则化</h3><h3 id="流形学习"><a href="#流形学习" class="headerlink" title="流形学习"></a>流形学习</h3><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/exacity/deeplearningbook-chinese" target="_blank" rel="external">Deep Learning Book</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;机器学习本质上属于应用统计学，更多关注于如何用计算机统计地估计复杂函数，不太关注这些函数的置信区间。&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="知识储备" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/"/>
    
    
      <category term="Book" scheme="http://luxialan.com/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>【深度学习】 读书笔记 拾一 深度模型中的优化</title>
    <link href="http://luxialan.com/2017/02/14/2017%E7%AC%AC%E4%B8%80%E8%B0%88/"/>
    <id>http://luxialan.com/2017/02/14/2017第一谈/</id>
    <published>2017-02-14T06:38:12.000Z</published>
    <updated>2017-03-16T03:09:54.000Z</updated>
    
    <content type="html"><![CDATA[<p>前馈神经网络对于机器学习的实践是极其重要的。<br><a id="more"></a></p>
<ul>
<li>性能度量</li>
<li>默认的基准模型</li>
<li>决定是否收集更多数据</li>
<li>选择超参数</li>
<li>调试技巧</li>
<li>实例：多位数字识别</li>
</ul>
<h2 id="实用方法"><a href="#实用方法" class="headerlink" title="实用方法"></a>实用方法</h2><p>应用深度学习技术不仅需要知道存在拿哪些算法和解释它们如何工作的原则，一个好的机器学习实践者也需要知道如何挑选一个针对特别应用的算法，以及如何监管和回应实验中得到的反馈以改进机器学习系统。<br>实践者需要决定</p>
<ul>
<li>是否收集更多的数据</li>
<li>增加或减少模型容量</li>
<li>添加或删除正则化功能</li>
<li>改进模型的优化</li>
<li>改进模型的近似推断</li>
<li>调试模型的软件实现</li>
</ul>
<p>##<br>在实践中，正确使用一个普通算法通常比草率使用一个不清楚的算法效果更好。</p>
<p>我们建议一下几个使用额设计流程</p>
<ul>
<li>你的目标</li>
<li>性能度量</li>
<li><em>
</em></li>
</ul>
<h2 id="默认的基准模型"><a href="#默认的基准模型" class="headerlink" title="默认的基准模型"></a>默认的基准模型</h2><p>## </p>
<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>卷积运算通过三个重要的思想来帮助改进机器学习系统：稀疏交互、参数共享、等变表示。<br>传统的神经网络使用矩阵乘法来建立输入与输出的连接关系。参数矩阵的每一个独立的参数都描述了每一个输入单元与每一个输出单元间的交互。这意味着每一个输出单元与每一个输入单元都产生交互。<br>这通过使得核的规模远小于输入的规模来实现。</p>
<h2 id="随机或无监督的特征"><a href="#随机或无监督的特征" class="headerlink" title="随机或无监督的特征"></a>随机或无监督的特征</h2><p>减少卷积网络训练成本的一种方式是使用那些不是通过有监督方式训练的特征。<br>有三种基本策略不通过有监督训练而得到卷积核。</p>
<ul>
<li>简单地随机初始化它们</li>
<li>手动设计它们</li>
<li>无监督的标准来学习核<h2 id="卷积神经网络与深度学习的历史"><a href="#卷积神经网络与深度学习的历史" class="headerlink" title="卷积神经网络与深度学习的历史"></a>卷积神经网络与深度学习的历史</h2>卷积网络在深度学习的历史中发挥了重要作用。它们是将研究大脑获得的深刻理解成功用于机器学习应用的关键例子。</li>
</ul>
<h2 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h2><h2 id="卷积与池化未做一种无限强的先验"><a href="#卷积与池化未做一种无限强的先验" class="headerlink" title="卷积与池化未做一种无限强的先验"></a>卷积与池化未做一种无限强的先验</h2><p>我们看到数据之前我们认为什么样的模型是合理的信念。<br>先验被认为是强或者弱取决于先验中概率密度的集中程度。弱先验具有较高的熵值，例如方差很大的高斯分布，这样的先验允许数据对于参数的改变具有或多或少的自由性。强先验具有较低的熵值，例如方差很小的高斯分布，这样的先验在决定参数最终取值时起着更加积极的作用。<br>对于全连接网络的权值有一个无限强的先验。这个无限强的先验是说一个隐藏单元的权值必须和它邻居的权值相等，但在 空间中改变。这个先验也要求除了那些处在隐藏单元空间连续的小的接受域以内的权值外，其余的权值都为零。使用池化也是一个无限强的先验：每一个单元都具有少量平移的不变性。<br>其中一个关键的洞察是卷积和池化可能导致欠拟合<br>另一个关键洞察是当我们比较卷积模型的统计学习表现时，指能以基准中的其他卷积模型作为比较的对象。</p>
<h2 id="基本卷积函数的变体"><a href="#基本卷积函数的变体" class="headerlink" title="基本卷积函数的变体"></a>基本卷积函数的变体</h2><hr>
<p>title: 【深度学习】 读书笔记 拾二 深度模型中的优化<br>date: 2017-02-14 14:38:12<br>categories: </p>
<ul>
<li>焚膏继晷</li>
<li>知识储备<br>tags: Book</li>
</ul>
<hr>
<p>前馈神经网络对于机器学习的实践是极其重要的。</p>
<h2 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h2><p>如何使用深度学习来解决计算机视觉，语音识别，自然语言处理以及其他商业领域中的应用。<br>尽管深度学习的一个目标是设计能够处理多种任务的算法，然而截止目前应用深度学习仍然需要一些特定的条件。比如说，计算机视觉中的额任务对每一个样本都需要大量的输入特征（像素）。自然语言处理中对每一个输入特征都需要大量的可能值（词汇表中的词汇）建模。</p>
<h2 id="大规模深度学习"><a href="#大规模深度学习" class="headerlink" title="大规模深度学习"></a>大规模深度学习</h2><p>深度学习的基本思想是建立在链接</p>
<h2 id="自动编码器"><a href="#自动编码器" class="headerlink" title="自动编码器"></a>自动编码器</h2><p>自动编码器是神经网络的一种，经过训练后尝试将输入复制到输出。自动编码器内部有一个隐含层$h$，可以产生$编码(code)$来表示输入。该网络可以看做由两部分组成：一个编码器函数$h=f(x)$和一个生成重构的解码器$r=g(h)$。如果一个自动编码器学会简单地设置$g(f(x))=x$，那么这个自动编码器不会很有用。相反，自动编码器应该被设计成不能学会完美地复制。这通常需要强加一些约束，使自动编码器应该被设计成不能学会完美地复制。强加一些约束，使自动编码器值能近似地复制，并只能复制类似训练数据的输入。划定输入数据不同方面的主次次序，有用特性。</p>
<p>随机算法可以粗略地分为两类：$Las Vegas$算法和蒙特卡洛算法</p>
<h2 id="采样和蒙特卡洛方法"><a href="#采样和蒙特卡洛方法" class="headerlink" title="采样和蒙特卡洛方法"></a>采样和蒙特卡洛方法</h2><h3 id="为什么需要采样？"><a href="#为什么需要采样？" class="headerlink" title="为什么需要采样？"></a>为什么需要采样？</h3><h3 id="玻尔兹曼机"><a href="#玻尔兹曼机" class="headerlink" title="玻尔兹曼机"></a>玻尔兹曼机</h3><p>第二十章 深度生成模型</p>
<h2 id="玻尔兹曼机-1"><a href="#玻尔兹曼机-1" class="headerlink" title="玻尔兹曼机"></a>玻尔兹曼机</h2><p>用来学习二值向量上的任意概率分布。我们简要介绍二值玻尔兹曼机并讨论训练模型和执行推断时出现的问题。<br>我们在$d$维二值随机变量$x\in{0,1}^{d}$上定义玻尔兹曼机。<br>意味着$$P(x)=/frac{exp(-E(x))}{Z}$$<br>其中$E(x)$是能量函数，$Z$是确保$P(x)=1$的配分函数。<br>玻尔兹曼机的能量函数如下给出：<br>$$E(x)=-x^{T}Ux-b^{T}x$$<br>当不是所有变量都能被观察到时，玻尔兹曼机变得更强大。在这种情况下，隐变量类似于多层感知机中的隐藏单元，并模拟可见单元之间的高阶交互。玻尔兹曼机变成了离散变量的概率分布律函数的通用比逼近器。<br>我们将单元$x$分解成两个子集：可见单元$v$和隐含单元$h$，能量函数变为<br>$$E(v,h)=-v^{T}Rv-v^{T}Wh-h^{T}Sh-b^{T}v-c^{T}h$$<br>玻尔兹曼机的学习</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前馈神经网络对于机器学习的实践是极其重要的。&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="知识储备" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/"/>
    
    
      <category term="Book" scheme="http://luxialan.com/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>【深度学习】 读书笔记 捌 深度模型中的优化</title>
    <link href="http://luxialan.com/2017/02/14/%E5%85%A8%E6%A0%88%E5%B7%A5%E7%A8%8B%E5%B8%88%E6%8C%87%E5%8D%97/"/>
    <id>http://luxialan.com/2017/02/14/全栈工程师指南/</id>
    <published>2017-02-14T06:38:12.000Z</published>
    <updated>2017-03-16T03:09:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>前馈神经网络对于机器学习的实践是极其重要的。<br><a id="more"></a></p>
<ul>
<li>卷积运算</li>
<li>动机</li>
<li>池化</li>
<li>卷积与池化作为一种无限强的先验</li>
<li>基本卷积函数的变体</li>
<li>结构化输出</li>
<li>数据类型</li>
<li>高效的卷积算法</li>
<li>随机或无监督的特征</li>
<li>卷积神经网络的神经科学基础</li>
<li>卷积神经网络与深度学习的历史</li>
</ul>
<p>##<br>卷积网络，也叫做卷积神经网络，是一种专门用来处理具有类似网格结构的数据的神经网络。卷积是一种特殊的线性运算。卷积网络是指那些至少在网络的一层中使用卷积运算来替代一般的矩阵乘法运算的神经网络。</p>
<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>卷积运算通过三个重要的思想来帮助改进机器学习系统：稀疏交互、参数共享、等变表示。<br>传统的神经网络使用矩阵乘法来建立输入与输出的连接关系。参数矩阵的每一个独立的参数都描述了每一个输入单元与每一个输出单元间的交互。这意味着每一个输出单元与每一个输入单元都产生交互。<br>这通过使得核的规模远小于输入的规模来实现。</p>
<h2 id="随机或无监督的特征"><a href="#随机或无监督的特征" class="headerlink" title="随机或无监督的特征"></a>随机或无监督的特征</h2><p>减少卷积网络训练成本的一种方式是使用那些不是通过有监督方式训练的特征。<br>有三种基本策略不通过有监督训练而得到卷积核。</p>
<ul>
<li>简单地随机初始化它们</li>
<li>手动设计它们</li>
<li>无监督的标准来学习核<h2 id="卷积神经网络与深度学习的历史"><a href="#卷积神经网络与深度学习的历史" class="headerlink" title="卷积神经网络与深度学习的历史"></a>卷积神经网络与深度学习的历史</h2>卷积网络在深度学习的历史中发挥了重要作用。它们是将研究大脑获得的深刻理解成功用于机器学习应用的关键例子。</li>
</ul>
<h2 id="池化"><a href="#池化" class="headerlink" title="池化"></a>池化</h2><h2 id="卷积与池化未做一种无限强的先验"><a href="#卷积与池化未做一种无限强的先验" class="headerlink" title="卷积与池化未做一种无限强的先验"></a>卷积与池化未做一种无限强的先验</h2><p>我们看到数据之前我们认为什么样的模型是合理的信念。<br>先验被认为是强或者弱取决于先验中概率密度的集中程度。弱先验具有较高的熵值，例如方差很大的高斯分布，这样的先验允许数据对于参数的改变具有或多或少的自由性。强先验具有较低的熵值，例如方差很小的高斯分布，这样的先验在决定参数最终取值时起着更加积极的作用。<br>对于全连接网络的权值有一个无限强的先验。这个无限强的先验是说一个隐藏单元的权值必须和它邻居的权值相等，但在 空间中改变。这个先验也要求除了那些处在隐藏单元空间连续的小的接受域以内的权值外，其余的权值都为零。使用池化也是一个无限强的先验：每一个单元都具有少量平移的不变性。<br>其中一个关键的洞察是卷积和池化可能导致欠拟合<br>另一个关键洞察是当我们比较卷积模型的统计学习表现时，指能以基准中的其他卷积模型作为比较的对象。</p>
<h2 id="基本卷积函数的变体"><a href="#基本卷积函数的变体" class="headerlink" title="基本卷积函数的变体"></a>基本卷积函数的变体</h2><p>学习和优化有什么不同<br>机器学习通常是简介的。在大多数机器学习问题中，我们关注定义于测试集上的，也可能是不可解的性能度量$P$。因此，我们只是简介地优化$P$。我们希望通过降低损失函数$J(\theta)$来提高$P$。这一点不同于纯优化最小化$J$本身。<br>$$J(\theta)=\mathtt{E}_{(x,y)~\hat{p}_data}L(f(x;\theta),y)$$<br>其中$L$是每个样本的损失函数，$f(x;\theta)$是输入是$x$时的预测输出，$\hat{p}_data$是经验分布。<br>通常，我们更希望最小化期望取自数据生成分布$p<em>data$，$$J^{*}(\theta)=\mathtt{E}</em>{(x,y)~\hat{p}_data}L(f(x;\theta),y)$$</p>
<h2 id="经验风险最小化"><a href="#经验风险最小化" class="headerlink" title="经验风险最小化"></a>经验风险最小化</h2><p>机器学习算法的目标是降低式(8.2)所示的期望泛化误差。这个数据量被称为风险(risk)。值得注意的是，该期望取自真实的数据分布$p<em>data$。<br>机器学习问题用训练集上的经验分布$\hat{p}(x,y)$替代真实分布$p(x,y)$。如此，我们最小化经验风险$$\mathtt{E}</em>{(x,y)~\hat{p}_data}L(f(x;\theta),y)=frac{1}{m}\$$<br>基于最小化如上平均训练误差的训练过程被称为经验风险最小化。<br>经验风险最小化容易过拟合。高容量的模型会简单地记住训练集。在很多情况下，经验风险最小化并非真的可行。最有效的现代优化算法是基于梯度下降的。在深度学习中我们很少使用经验风险最小化。</p>
<h2 id="替代损失函数和提前终止"><a href="#替代损失函数和提前终止" class="headerlink" title="替代损失函数和提前终止"></a>替代损失函数和提前终止</h2><h2 id="（小）批算法"><a href="#（小）批算法" class="headerlink" title="（小）批算法"></a>（小）批算法</h2><p>机器学习算法的目标函数通常可以分解成训练样本上的求和。机器学习优化算法通常使用整个损失函数中的一部分项去更新其参数。</p>
<h2 id="神经网络的优化挑战"><a href="#神经网络的优化挑战" class="headerlink" title="神经网络的优化挑战"></a>神经网络的优化挑战</h2><p>在训练神经网络时，我们肯定会遇到一般的非凸情况。即使是凸优化，也并非没有任何问题。在这一节中，我们会总结几个训练深度模型时会涉及到的主要挑战。</p>
<h3 id="8-2-1-病态"><a href="#8-2-1-病态" class="headerlink" title="8.2.1 病态"></a>8.2.1 病态</h3><p>海森矩阵$H$的病态。这是数值优化，凸优化或其他形式的优化中普遍存在的问题。<br>病态体现在随机梯度下降会“卡”在某些情况，此时即使很小的更新步长也会增加损失函数。</p>
<h3 id="8-2-2-局部极小值"><a href="#8-2-2-局部极小值" class="headerlink" title="8.2.2 局部极小值"></a>8.2.2 局部极小值</h3><h3 id="8-2-3-高原，鞍点和其他平坦区域"><a href="#8-2-3-高原，鞍点和其他平坦区域" class="headerlink" title="8.2.3 高原，鞍点和其他平坦区域"></a>8.2.3 高原，鞍点和其他平坦区域</h3><h3 id="8-2-4-悬崖和梯度爆炸"><a href="#8-2-4-悬崖和梯度爆炸" class="headerlink" title="8.2.4 悬崖和梯度爆炸"></a>8.2.4 悬崖和梯度爆炸</h3><p>多层神经网络通常有像悬崖一样的斜率较大区域，如图8.3所示。这是由于几个较大的权重相乘导致的。遇到斜率极大的悬崖结构时，梯度更新会很大程度地改变参数值，通常会跳过这类悬崖结构。但幸运的是可以使用启发式梯度截断来避免其主要缺点。</p>
<h3 id="8-2-5-长期相关性"><a href="#8-2-5-长期相关性" class="headerlink" title="8.2.5 长期相关性"></a>8.2.5 长期相关性</h3><p>反复使用相同的参数产生了尤为突出的困难。<br>重复与矩阵$W$相乘的路径。<br>当特征值$\lambda_i$不再$1$附近时，若在量级上大于1则会膨胀到很大；若小于1时则会收缩到很小。<br>收缩和膨胀的梯度问题是指计算图上的梯度也会因为$diag(\lambda)^{t}$，诱发梯度截断的悬崖结构便是膨胀梯度现象的一个例子。<br>从这个观点来看，</p>
<h2 id="8-3-基本算法"><a href="#8-3-基本算法" class="headerlink" title="8.3 基本算法"></a>8.3 基本算法</h2><h3 id="8-3-1-随机梯度下降"><a href="#8-3-1-随机梯度下降" class="headerlink" title="8.3.1 随机梯度下降"></a>8.3.1 随机梯度下降</h3><p>通过计算独立同分布地从数据生成分布中抽取的$m$个$minibatch$样本的梯度均值，我们可以得到梯度的无偏估计。在实践中，有必要随着时间的推移逐渐降低学习速率。<br>通常，就总训练时间和最终损失值而言，最优初始学习速率会高于大约迭代100步后输出最好效果的学习速率。<br>对于足够大的数据集，$SGD$可能会在处理整个训练集之前就收敛到最终测试集误差的某个固定容差范围内。<br>算法的收敛率，即当前损失函数超出最低可能损失的量。$batch$梯度下降在理论上比随机梯度下降有更好的收敛率。</p>
<h3 id="动量"><a href="#动量" class="headerlink" title="动量"></a>动量</h3><h3 id="Nesterov-动量"><a href="#Nesterov-动量" class="headerlink" title="Nesterov 动量"></a>Nesterov 动量</h3><h2 id="参数初始化策略"><a href="#参数初始化策略" class="headerlink" title="参数初始化策略"></a>参数初始化策略</h2><p>大多数初始化策略基于在神经网络初始化时实现一些很好的性质。我们没有很好地理解这些性质中的哪些会在学习开始进行后的哪些情况下得以保持。进一步的难点是，有些初始点从优化的观点看或许是有利的，但是从泛化的观点看是不利的。我们对于初始点如何影响泛化的理解是相当原始的，几乎没有提供如何选择初始点的任何指导。<br>也许完全确指的唯一特性是初始参数需要在不同单元间“破坏对称性”。<br>如果我们有和输出一样多的输入，我们可以使用$Gram-Schmidt$正交化于初始的权重矩阵，保证每个单元计算彼此非常不同的函数。在高纬空间上使用高熵分布来随机初始化，计算代价小而且不太可能分配单元计算彼此相同的函数。<br>我们几乎总是初始化模型的权重为高斯或均匀分布中随机抽取的值。初始分布的大小确实对优化过程的结果和网络泛化能力有很大的影响。<br>更大的初始权重具有更强的破坏对称性的作用，有助于避免冗余的单元。正则化和优化有非常不同的视角。优化视角建议权重应该足够大以成功传播信息，但是正则化希望其小一点。诸如随机梯度下降这类对权重较小的增量更新，趋于停止在更靠近的初始参数的区域。</p>
<h2 id="自适应学习率的算法"><a href="#自适应学习率的算法" class="headerlink" title="自适应学习率的算法"></a>自适应学习率的算法</h2><p>学习率是难以设置的超参数之一，因为它对模型的性能有显著的影响。<br>$delta-bar-delta算法$，该方法基于一个很简单的想法，如果损失对于某个给定模型参数的偏导保持相同的符号，那么学习速率应该增加。</p>
<h3 id="AdaGrad"><a href="#AdaGrad" class="headerlink" title="AdaGrad"></a>AdaGrad</h3><p>$AdaGrad$算法。放缩每个参数反比于其所有梯度历史平方值总和的平方根。具有损失最大偏导的参数相应地有一个快速下降的学习速率，而具有小偏导的参数在学习速率上有较小的下降。</p>
<h3 id="RMSProp"><a href="#RMSProp" class="headerlink" title="RMSProp"></a>RMSProp</h3><p>$RMSProp$算法修改$AdaGrad$以在非凸设定下效果更好。</p>
<h3 id="Adam"><a href="#Adam" class="headerlink" title="Adam"></a>Adam</h3><p>$Adam$</p>
<h2 id="选择正确的优化算法"><a href="#选择正确的优化算法" class="headerlink" title="选择正确的优化算法"></a>选择正确的优化算法</h2><h2 id="二阶近似方法"><a href="#二阶近似方法" class="headerlink" title="二阶近似方法"></a>二阶近似方法</h2><h3 id="牛顿方法"><a href="#牛顿方法" class="headerlink" title="牛顿方法"></a>牛顿方法</h3><h3 id="共轭梯度"><a href="#共轭梯度" class="headerlink" title="共轭梯度"></a>共轭梯度</h3><h2 id="优化技巧和元算法"><a href="#优化技巧和元算法" class="headerlink" title="优化技巧和元算法"></a>优化技巧和元算法</h2><h3 id="batch-normalization"><a href="#batch-normalization" class="headerlink" title="batch normalization"></a>batch normalization</h3><h3 id="坐标下降"><a href="#坐标下降" class="headerlink" title="坐标下降"></a>坐标下降</h3><h3 id="Polyak-平均"><a href="#Polyak-平均" class="headerlink" title="Polyak 平均"></a>Polyak 平均</h3>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;前馈神经网络对于机器学习的实践是极其重要的。&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="知识储备" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/"/>
    
    
      <category term="Book" scheme="http://luxialan.com/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>【深度学习】 读书笔记 肆 数值计算</title>
    <link href="http://luxialan.com/2017/02/13/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E8%82%86-%E6%95%B0%E5%80%BC%E8%AE%A1%E7%AE%97/"/>
    <id>http://luxialan.com/2017/02/13/【深度学习】-读书笔记-肆-数值计算/</id>
    <published>2017-02-13T11:08:27.000Z</published>
    <updated>2017-02-23T06:39:06.000Z</updated>
    
    <content type="html"><![CDATA[<p>机器学习算法需要数值计算的方法来迭代求解无解析解的数学问题。包括优化和线性方程组求解。<br><a id="more"></a></p>
<ul>
<li>1.上溢和下溢</li>
<li>2.病态条件数</li>
<li>3.基于梯度的优化方法</li>
<li>4.约束优化</li>
<li>5.实例：线性最小二乘</li>
</ul>
<h2 id="上溢和下溢"><a href="#上溢和下溢" class="headerlink" title="上溢和下溢"></a>上溢和下溢</h2><p>在数字计算机上实现连续数学的根本困难是，我们需要通过有限数量的位模式来表示无限多的实数。<br>一种特别地毁灭性舍入误差是下溢(underflow)，当接近零的数被四舍五入为零时发生下溢。<br>另一种极具破坏力的数值错误形式是上溢。当大量级的数被近似为$\infty$<br>必须对上溢和下溢进行数值稳定的一个例子是\bm{softmax函数}(softmax function)。softmax 函数经常用于预测与多项式分布相关的概率，定义为：<br>$softmax(\bold{x})_i=\frac{exp(x<em>i)}{\sum</em>{j=1}^{n}exp(x_j)}$</p>
<h2 id="病态条件数"><a href="#病态条件数" class="headerlink" title="病态条件数"></a>病态条件数</h2><p>条件数表明函数相对于输入的微小变化而变化的快慢程度。输入被轻微扰动而迅速改变的函数对于科学计算来说是可能是有问题的，因为输入中的舍入误差可能导致输出的巨大变化。<br>考虑$f(x)=A^{-1}x$。当$A\in\mathbb{R}^(nXn)$具有特征分解时，其条件数为$max_{i,j}|{\frac{\lambda_i}{\lambda_j}}|$<br>这是最大和最小特征值的模的比。当该数很大时，矩阵求逆对输入的误差特别敏感。</p>
<h2 id="基于梯度的优化方法"><a href="#基于梯度的优化方法" class="headerlink" title="基于梯度的优化方法"></a>基于梯度的优化方法</h2><p>我们把最大化或最小化的函数称为目标函数或准则。<br>导数<br>临界点或驻点</p>
<h2 id="基于梯度的优化方法-1"><a href="#基于梯度的优化方法-1" class="headerlink" title="基于梯度的优化方法"></a>基于梯度的优化方法</h2><h2 id="约束优化"><a href="#约束优化" class="headerlink" title="约束优化"></a>约束优化</h2><h2 id="实例：线性最小二乘"><a href="#实例：线性最小二乘" class="headerlink" title="实例：线性最小二乘"></a>实例：线性最小二乘</h2><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/exacity/deeplearningbook-chinese" target="_blank" rel="external">Deep Learning Book</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;机器学习算法需要数值计算的方法来迭代求解无解析解的数学问题。包括优化和线性方程组求解。&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="知识储备" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/"/>
    
    
      <category term="Book" scheme="http://luxialan.com/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>【深度学习】 读书笔记 叁 概率与信息论</title>
    <link href="http://luxialan.com/2017/02/12/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E5%8F%81-%E6%A6%82%E7%8E%87%E4%B8%8E%E4%BF%A1%E6%81%AF%E8%AE%BA/"/>
    <id>http://luxialan.com/2017/02/12/【深度学习】-读书笔记-叁-概率与信息论/</id>
    <published>2017-02-12T10:35:13.000Z</published>
    <updated>2017-02-23T06:37:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>概率论使我们能够作出不确定的陈述以及在不确定性存在的情况下推理，而信息论使我们能够量化概率分布中的不确定性总量。<br><a id="more"></a></p>
<h2 id="为什么要用概率？"><a href="#为什么要用概率？" class="headerlink" title="为什么要用概率？"></a>为什么要用概率？</h2><p>世界是不确定的，要对世界中的活动进行建模需要用概率论来量化不确定性。<br>不确定性有三种可能的来源：</p>
<ul>
<li>被建模系统内在的随机性。</li>
<li>不完全观测。即使是确定的系统，当我们不能观测到所有驱动系统行为的变量时，该系统也会呈现随机性。</li>
<li>不完全建模。使用一些必须舍弃某些观测信息的建模时，舍弃的信息会导致模型的预测出现不确定性。</li>
</ul>
<p>在很多情况下，使用一些简单而不确定的原则要比复杂而确定的原则更为实用，即使真实的规则是确定的并且我们的模型系统对适应复杂规则具有很好的逼真度。<br>有两种概率，一种概率，直接与事件发生的频率相联系，称为频率概率；另一种概率，涉及到确定性水平，被称为贝叶斯概率。</p>
<h2 id="随机变量"><a href="#随机变量" class="headerlink" title="随机变量"></a>随机变量</h2><p>随机变量(random variable)是可以随机地取不同值的变量。<br>一种随机变量只是对可能的状态的描述；它必须伴随着一个概率分布来指定每个状态的可能性。</p>
<h2 id="概率分布"><a href="#概率分布" class="headerlink" title="概率分布"></a>概率分布</h2><p>概率分布(probability distribution)用来描述随机变量或一簇随机变量在每一个可能取到的状态的可能性大小。</p>
<h3 id="离散型变量和概率分布律函数"><a href="#离散型变量和概率分布律函数" class="headerlink" title="离散型变量和概率分布律函数"></a>离散型变量和概率分布律函数</h3><p>离散型变量的概率分布可以用概率分布律函数(probability mass function,PMF)来描述。我们通常用$P$来表示概率分布律函数。用$x$~$P(x)$表示随机变量x服从P分布。<br>概率分布律函数可以同时作用于多个随机变量。这种多个变量的概率分布被称为联合概率分布(joint probability distribution)。</p>
<h3 id="连续型变量和概率密度函数"><a href="#连续型变量和概率密度函数" class="headerlink" title="连续型变量和概率密度函数"></a>连续型变量和概率密度函数</h3><h2 id="边缘概率"><a href="#边缘概率" class="headerlink" title="边缘概率"></a>边缘概率</h2><p>我们知道了一组变量的联合概率分布，想要了解其中一个子集的概率分布。这种定义在子集上的概率分布被称为边缘概率分布(marginal probability)。对于连续型变量，我们需要用积分替代求和：$$p(x)=\int p(x,y)dy$$</p>
<h2 id="条件概率"><a href="#条件概率" class="headerlink" title="条件概率"></a>条件概率</h2><p>$P($y$=y)|$x$=x)=\frac{P(\boldsymbol{y}=y,\boldsymbol{x}=x)}{P(\boldsymbol{x}=x)}$</p>
<h2 id="条件概率的链式法则"><a href="#条件概率的链式法则" class="headerlink" title="条件概率的链式法则"></a>条件概率的链式法则</h2><h2 id="独立性和条件独立性"><a href="#独立性和条件独立性" class="headerlink" title="独立性和条件独立性"></a>独立性和条件独立性</h2><h2 id="期望，方差和协方差"><a href="#期望，方差和协方差" class="headerlink" title="期望，方差和协方差"></a>期望，方差和协方差</h2><h2 id="常用概率分布"><a href="#常用概率分布" class="headerlink" title="常用概率分布"></a>常用概率分布</h2><h3 id="Bernoulli分布"><a href="#Bernoulli分布" class="headerlink" title="Bernoulli分布"></a>Bernoulli分布</h3><ul>
<li>$P(\boldsymbol{x}=x)=\phi^x(1-\phi)^{1-x}$</li>
<li>$P(\boldsymbol{x}=0)=1-\phi$</li>
<li>$P(\boldsymbol{x}=1)=\phi$</li>
<li>$\mathbb{E}_x=\phi$</li>
<li>$Var_x(x)=\phi(1-\phi)$</li>
</ul>
<h3 id="多项式分布"><a href="#多项式分布" class="headerlink" title="多项式分布"></a>多项式分布</h3><h3 id="高斯分布-正态分布"><a href="#高斯分布-正态分布" class="headerlink" title="高斯分布/正态分布"></a>高斯分布/正态分布</h3><h3 id="指数分布和Laplace分布"><a href="#指数分布和Laplace分布" class="headerlink" title="指数分布和Laplace分布"></a>指数分布和Laplace分布</h3><h3 id="Dirac分布和经验分布"><a href="#Dirac分布和经验分布" class="headerlink" title="Dirac分布和经验分布"></a>Dirac分布和经验分布</h3><h3 id="分布的混合"><a href="#分布的混合" class="headerlink" title="分布的混合"></a>分布的混合</h3><h2 id="常用函数的一些性质"><a href="#常用函数的一些性质" class="headerlink" title="常用函数的一些性质"></a>常用函数的一些性质</h2><h2 id="贝叶斯规则"><a href="#贝叶斯规则" class="headerlink" title="贝叶斯规则"></a>贝叶斯规则</h2><h2 id="连续型变量的技术细节"><a href="#连续型变量的技术细节" class="headerlink" title="连续型变量的技术细节"></a>连续型变量的技术细节</h2><h2 id="信息论"><a href="#信息论" class="headerlink" title="信息论"></a>信息论</h2><p>信息论是应用数学的一个分支，主要研究的是对一个信号能够提供的多少进行量化。<br>信息论的基本想法是一个不太可能的事件居然发生了，要比一个非常可能的事件发生，能提供更多的信息。</p>
<ul>
<li>非常可能发生的事件信息量比较少，并且极端情况下，确保能够发生的事件应该没有信息量。</li>
<li>更不可能发生的事件要具有更高的信息量</li>
<li>独立事件应具有增量的信息。例如，投掷的硬币两次正面朝上传递的信息量应该是投掷一次硬币正面朝上的信息量的两倍。</li>
</ul>
<p>为了满足上述三个性质，我们定义一个事件$\rm{x}=x$的自信息(self-information)为$$I(x)=-logP(x)$$<br>我们定义$I(x)$单位是奈特(nats)。一奈特是以$/frac{1}{\epsilon}$的概率观测到一个事件时获得的信息量。<br>自信息只处理单个的输出，我们可以用香农熵(Shannon entropy)来对整个概率分布中的不确定性总量进行量化：<br>$H(x)=\mathbb{E}<em>{x~P}[I(x)]=-\mathbb{E}</em>{x~P}[logP(x)]$</p>
<h2 id="14-结构化概率模型"><a href="#14-结构化概率模型" class="headerlink" title="14.结构化概率模型"></a>14.结构化概率模型</h2><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/exacity/deeplearningbook-chinese" target="_blank" rel="external">Deep Learning Book</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;概率论使我们能够作出不确定的陈述以及在不确定性存在的情况下推理，而信息论使我们能够量化概率分布中的不确定性总量。&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="知识储备" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/"/>
    
    
      <category term="Book" scheme="http://luxialan.com/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>【深度学习】 读书笔记 贰 线性代数</title>
    <link href="http://luxialan.com/2017/02/09/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E8%B4%B0-%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0/"/>
    <id>http://luxialan.com/2017/02/09/【深度学习】-读书笔记-贰-线性代数/</id>
    <published>2017-02-09T11:56:12.000Z</published>
    <updated>2017-02-15T12:46:56.000Z</updated>
    
    <content type="html"><![CDATA[<p>代数、分析、几何、概率论，数学的基础知识。<br><a id="more"></a></p>
<ul>
<li>1.标量、向量、矩阵和张量</li>
<li>2.矩阵和向量相乘</li>
<li>3.单位矩阵和逆矩阵</li>
<li>4.线性相关和生成子空间</li>
<li>5.范数</li>
<li>6.特殊类型的矩阵和向量</li>
<li>7.特征分解</li>
<li>8.奇异值分解</li>
<li>9.Moore-Penrose伪逆</li>
<li>10.迹运算</li>
<li>11.行列式</li>
<li>12.主成分分析</li>
</ul>
<h2 id="标量、向量、矩阵和张量"><a href="#标量、向量、矩阵和张量" class="headerlink" title="标量、向量、矩阵和张量"></a>标量、向量、矩阵和张量</h2><p>标量：一个标量就是一个单独的数。<br>向量：一个向量是一列数。<br>矩阵：矩阵是二维数组。<br>张量：在某些情况下，我们会讨论不只两维坐标的数组。一般地，一组数组中的元素分布在若干维坐标的规则网格中，我们将其称之为张量。</p>
<h2 id="矩阵和向量相乘"><a href="#矩阵和向量相乘" class="headerlink" title="矩阵和向量相乘"></a>矩阵和向量相乘</h2><p>矩阵乘法</p>
<ul>
<li>$A(B+C)=AB+AC$</li>
<li>$A(BC)=(AB)C$</li>
<li>$(AB)^{T}=B^{T}A^{T}$<br>通过矩阵和向量来表示线性方程组</li>
<li>$Ax=b$</li>
</ul>
<h2 id="单位矩阵和逆矩阵"><a href="#单位矩阵和逆矩阵" class="headerlink" title="单位矩阵和逆矩阵"></a>单位矩阵和逆矩阵</h2><p>单位矩阵：任意向量和单位矩阵相乘，都不会改变。形式上，$I_n\in \mathtt{R} $,<br>$$\forall x\in \mathtt{R}, I_n x = x$$<br>单位矩阵结构简单：所有沿着主对角线的元素都是1，而其他位置的元素都是0，如<br>$$<br>\begin{bmatrix}<br>1 &amp; 0 &amp; 0 \<br>0 &amp; 1 &amp; 0 \<br>0 &amp; 0 &amp; 1 \<br>\end{bmatrix}<br>$$</p>
<h2 id="范数"><a href="#范数" class="headerlink" title="范数"></a>范数</h2><p>范数用来衡量向量的大小，是将向量映射到非负值的函数。<br>$L^p$范数定义如下：$$ ||x||_p=(\sum_i|x_i|^{p})^{\frac{1}{p}}$$<br>其中$p\in \mathtt{R},$p \geq 1$<br>范数可以是满足下列性质的任意函数：</p>
<ul>
<li>$f(x)=0$ =&gt; $x=0$</li>
<li>$f(x+y) \leq f(x) + f(y)$</li>
<li>$\forall \alpha \in \mathtt{R}, f(\alpha)=|\alpha|f(x)$ 当$p=2$时</li>
</ul>
<h3 id="特征分解"><a href="#特征分解" class="headerlink" title="特征分解"></a>特征分解</h3><p>我们可以通过分解质因数来发现一些关于整数的真实性质，我们也可以通过分解矩阵来获取矩阵表示成数组元素时不明显的函数性质。<br>特征分解是使用最广的矩阵分解之一，即我们将矩阵分解成一组特征向量和特征值。<br>方阵$A$的特征向量是指与$A$相乘后相当于对该向量进行放缩的非零向量：<br>$$Av=\lambda v$$<br>标量$\lambda$称为这个特征向量对应的特征值。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/exacity/deeplearningbook-chinese" target="_blank" rel="external">Deep Learning Book</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;代数、分析、几何、概率论，数学的基础知识。&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="知识储备" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/"/>
    
    
      <category term="Book" scheme="http://luxialan.com/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>【深度学习】 读书笔记 壹 深度学习概述</title>
    <link href="http://luxialan.com/2017/02/09/%E3%80%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%91-%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0-%E5%A3%B9-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0/"/>
    <id>http://luxialan.com/2017/02/09/【深度学习】-读书笔记-壹-深度学习概述/</id>
    <published>2017-02-09T05:56:12.000Z</published>
    <updated>2017-03-21T09:09:04.000Z</updated>
    
    <content type="html"><![CDATA[<p>深度学习的前世今生。<br><a id="more"></a><br>量化交易，也称算法交易，是严格按照计算机算法程序给出的买卖决策进行的证券交易。</p>
<p>量化交易与</p>
<ul>
<li>易扩大</li>
<li>节省时间</li>
<li>营销非必需</li>
</ul>
<h2 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h2><ul>
<li>对基本策略变形</li>
<li>真正困难的地方并不是缺乏交易理念，而是缺乏甄别策略的能力。<h3 id="有效的策略"><a href="#有效的策略" class="headerlink" title="有效的策略"></a>有效的策略</h3></li>
<li>工作时间</li>
<li>编程水平</li>
<li>交易资本</li>
<li>目标<h3 id="不可行的策略"><a href="#不可行的策略" class="headerlink" title="不可行的策略"></a>不可行的策略</h3></li>
<li>策略与基准相比如何？收益持续性如何。</li>
</ul>
<p>使用夏普比率或信息比率作为量化交易策略的业绩衡量指标<br>信息比率=超额收益率的均值/超额收益率的标准差<br>超额收益率=组合收益率-基准收益率</p>
<ul>
<li>策略的年交易次数有限，夏普比率可能就不会太高。</li>
<li>策略的挫跌很大，或是挫跌时间很长，也不大可能有很高的夏普比率。<h3 id="交易成本如何影响策略"><a href="#交易成本如何影响策略" class="headerlink" title="交易成本如何影响策略"></a>交易成本如何影响策略</h3></li>
<li>交易成本不仅包括经纪商收取的佣金，还包括流动性成本。<h3 id="数据有无存活偏差"><a href="#数据有无存活偏差" class="headerlink" title="数据有无存活偏差"></a>数据有无存活偏差</h3></li>
<li>股票价格的历史数据库往往不包括那些由于破产、退市、兼并或收购而消失的股票，因此存在所谓的存货偏差。<h3 id="策略的业绩如何随时间变化而变化？"><a href="#策略的业绩如何随时间变化而变化？" class="headerlink" title="策略的业绩如何随时间变化而变化？"></a>策略的业绩如何随时间变化而变化？</h3></li>
<li>状态转换应该也被纳入复杂模型<h3 id="过拟合问题"><a href="#过拟合问题" class="headerlink" title="过拟合问题"></a>过拟合问题</h3>统计学意义上相互独立的金融数据的数量是非常有限的，有效的AI方法有以下特征。</li>
<li>基于正确的计量经济学或理论基础，而不是随机发现的模式。</li>
<li>所需的参数用到历史数据较少</li>
<li>只用到了线性回归，并未使用复杂的非线性函数</li>
<li>概念上很简单</li>
<li>所有优化都必须在不含未来未知数据的移动回顾窗口中实现，并且这种优化的效果必须不断地被未来未知的数据所证实。<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2>如何找到潜在的交易策略：</li>
<li>商学院或其他经济研究机构的网站。</li>
<li>面向零售投资者的金融网站和博客。</li>
<li>可与其他交易员交流心得的交易员论坛。<br>如何筛选策略：</li>
<li>你有多少时间可以用来完善你的交易程序</li>
<li>你的编程能力如何</li>
<li>你的资本规模有多大</li>
<li>你的目标是稳定的月度收入还是追求大额的长期资本收益？<br>合适的策略：</li>
<li>它能否跑赢基准</li>
<li>它有足够高的夏普比率吗？</li>
<li>它有足够小的挫跌和足够短的挫跌期吗？</li>
<li>回测有无存活偏差？</li>
<li>与早年相比，策略近几年不灵了吗？</li>
<li>策略具有避开基金经理激烈竞争的“特色”吗？<h2 id="回测"><a href="#回测" class="headerlink" title="回测"></a>回测</h2><h3 id="回测平台-感觉很老了"><a href="#回测平台-感觉很老了" class="headerlink" title="回测平台(感觉很老了)"></a>回测平台(感觉很老了)</h3></li>
<li>Excel</li>
<li>MATLAB</li>
<li>TradeStation<h3 id="回测数据"><a href="#回测数据" class="headerlink" title="回测数据"></a>回测数据</h3></li>
<li>注意事项一：数据是否经分拆及股息调整</li>
<li>注意事项二：数据有无存活偏差</li>
<li>注意事项三：实盘价而不是最高、最低价<h3 id="业绩度量"><a href="#业绩度量" class="headerlink" title="业绩度量"></a>业绩度量</h3><h3 id="回测陷阱"><a href="#回测陷阱" class="headerlink" title="回测陷阱"></a>回测陷阱</h3></li>
<li>前视偏差</li>
<li>数据过拟合。构建数据驱动模型时，几乎不可能消除过拟合</li>
<li>敏感性分析<h3 id="策略改进"><a href="#策略改进" class="headerlink" title="策略改进"></a>策略改进</h3></li>
<li>策略的改进，最好基于经济学基本原理，或者透彻研究过的市场现象，而不是依据一些主观的试错法则。否则，就有可能产生数据过拟合。<h3 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h3>回测会牵扯到许多细节问题，如：</li>
<li>数据：分拆和股息的调整，日最高、最低价的噪声，存活偏差。</li>
<li>业绩度量：年化夏普比率和最大挫跌。</li>
<li>前视偏差：在过去的交易决策中使用无法得到的事后信息。</li>
<li>数据迁就偏差：拟合历史数据时使用过多参数，可以用大样本数据、样本外测试和敏感性分析来避免此类偏差。</li>
<li>交易成本：交易成本会影响策略业绩。</li>
<li>策略改进：通过策略的微小调整来优化业绩的常见方法。<h2 id="创建交易业务"><a href="#创建交易业务" class="headerlink" title="创建交易业务"></a>创建交易业务</h2>零售经纪商可以给予完全的自由和更好的资本保护，但杠杆低；自营交易公司给予的自由和资本保护较少，但杠杆高。<br>无论是选择零售经纪商还是选择自营交易公司，都要确保交易账户和系统满足以下特征：</li>
<li>相对较低的佣金</li>
<li>可交易金融工具品种广泛</li>
<li>有足够深度的流动资金池</li>
<li>最重要的是，获取实时数据和传送指令的API<br>交易员的操作环境包括：</li>
<li>一台双核或四核电脑</li>
<li>高速网络</li>
<li>防中断电源</li>
<li>实时数据和新闻来源</li>
<li>服务器托管<h2 id="自动交易系统的功能"><a href="#自动交易系统的功能" class="headerlink" title="自动交易系统的功能"></a>自动交易系统的功能</h2></li>
</ul>
<h2 id="资金和风险管理"><a href="#资金和风险管理" class="headerlink" title="资金和风险管理"></a>资金和风险管理</h2><ul>
<li>最优资本配置和杠杆</li>
<li></li>
</ul>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://github.com/exacity/deeplearningbook-chinese" target="_blank" rel="external">Deep Learning Book</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;深度学习的前世今生。&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="知识储备" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87/"/>
    
    
      <category term="Book" scheme="http://luxialan.com/tags/Book/"/>
    
  </entry>
  
  <entry>
    <title>服务器集群搭建与运维技术指南</title>
    <link href="http://luxialan.com/2016/12/29/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%9B%86%E7%BE%A4%E6%8C%87%E5%8D%97/"/>
    <id>http://luxialan.com/2016/12/29/服务器集群指南/</id>
    <published>2016-12-29T02:07:09.000Z</published>
    <updated>2017-01-22T13:58:54.000Z</updated>
    
    <content type="html"><![CDATA[<p>研究生期间协助导师搭建和管理实验室的服务器，其中涉及到基础的服务器集群搭建、管理和维护。由于时间有限，只总结出一个大的框架，仅供参考。<br><a id="more"></a></p>
<h2 id="服务器集群搭建"><a href="#服务器集群搭建" class="headerlink" title="服务器集群搭建"></a>服务器集群搭建</h2><h3 id="服务集群拓扑图"><a href="#服务集群拓扑图" class="headerlink" title="服务集群拓扑图"></a>服务集群拓扑图</h3><p><center> <img src="/images/server/server_topology.png" alt="Alt text"></center><br>一个服务器集群应当有一台以上的数据中心存储数据Data Server，Data Server特点是存储量尽可能大而运算能力可以不必太高，另外多台服务器作为运行程序的Work Server,根据不同的需求配置Work Server.</p>
<h2 id="服务器集群管理"><a href="#服务器集群管理" class="headerlink" title="服务器集群管理"></a>服务器集群管理</h2><h3 id="Linux服务器管理三步曲"><a href="#Linux服务器管理三步曲" class="headerlink" title="Linux服务器管理三步曲"></a>Linux服务器管理三步曲</h3><ul>
<li>1.初学乍道：Linux基本知识</li>
<li>2.初窥门径：Shell脚本编程</li>
<li>3.登堂入室：Pssh并行管理</li>
</ul>
<h4 id="1-初学乍道：Linux基本知识"><a href="#1-初学乍道：Linux基本知识" class="headerlink" title="1.初学乍道：Linux基本知识"></a>1.初学乍道：Linux基本知识</h4><p>linux的常用的命令如下：<br>查看服务器基本信息<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ top</div></pre></td></tr></table></figure></p>
<p><center> <img src="/images/server/top.png" alt="Alt text"></center><br>top的升级版<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ htop</div></pre></td></tr></table></figure></p>
<p><center> <img src="/images/server/htop.png" alt="Alt text"></center><br>查看当前目录下文件信息<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ ls</div></pre></td></tr></table></figure></p>
<p>更改目录<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ <span class="built_in">cd</span></div></pre></td></tr></table></figure></p>
<p>新建文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ mkdir</div></pre></td></tr></table></figure></p>
<p>删除文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ rm</div></pre></td></tr></table></figure></p>
<p>复制文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ cp</div></pre></td></tr></table></figure></p>
<p>移动文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ mv</div></pre></td></tr></table></figure></p>
<p>查找文件<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ find</div></pre></td></tr></table></figure></p>
<p>切换用户<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ su root</div><div class="line">Password:</div><div class="line">root@grus:/home/luxi<span class="comment">#</span></div></pre></td></tr></table></figure></p>
<p>更改文件使用权限<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ chmod</div></pre></td></tr></table></figure></p>
<p>挂载<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ mount</div></pre></td></tr></table></figure></p>
<p>远程登录其他服务器<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">luxi@grus:~$ ssh</div></pre></td></tr></table></figure></p>
<p>更多基本基本命令参考<a href="http://cn.linux.vbird.org/" target="_blank" rel="external">《鸟哥的私房菜》</a></p>
<h4 id="2-初窥门径：Shell脚本编程"><a href="#2-初窥门径：Shell脚本编程" class="headerlink" title="2.初窥门径：Shell脚本编程"></a>2.初窥门径：Shell脚本编程</h4><p>Shell脚本编程可以看做为基本命令组合而成的复杂命令，其存在的价值在于封装好复杂命令，使用户能够通过运行脚本来执行复杂命令，避免了重复编程。是自动化管理服务器的重要一步。</p>
<h4 id="3-登堂入室：Pssh并行管理"><a href="#3-登堂入室：Pssh并行管理" class="headerlink" title="3.登堂入室：Pssh并行管理"></a>3.登堂入室：Pssh并行管理</h4><p><a href="https://code.google.com/archive/p/parallel-ssh/" target="_blank" rel="external">PSSH(parallel-ssh)</a>是一个python编写的在多台服务器上执行命令的轻量级管理工具。其实运用Shell脚本语言，我们完全可以自己从头实现一个类似的工具（通过ssh+特定命令），然而可以避免重复造轮子的话还是尽量避免。<br>例子：pssh实现查看多台服务器运行情况</p>
<p><center> <img src="/images/server/pssh.png" alt="Alt text"></center></p>
<h2 id="服务器集群维护"><a href="#服务器集群维护" class="headerlink" title="服务器集群维护"></a>服务器集群维护</h2><p><a href="https://wiki.tankywoo.com/#tool" target="_blank" rel="external">常用工具</a></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>个人感觉服务器集群的搭建和维护的三个核心是监控、安全和自动化。</p>
<ul>
<li>1.监控指的是能及时的获取服务器集群的信息并从中发现异常。</li>
<li>2.安全指的服务器集群数据的权限管理和备份管理。</li>
<li>2.自动化指的是服务器集群的管理和维护应该借助工具和脚本避免重复造轮子。</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;研究生期间协助导师搭建和管理实验室的服务器，其中涉及到基础的服务器集群搭建、管理和维护。由于时间有限，只总结出一个大的框架，仅供参考。&lt;br&gt;
    
    </summary>
    
      <category term="焚膏继晷" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/"/>
    
      <category term="技术管理" scheme="http://luxialan.com/categories/%E7%84%9A%E8%86%8F%E7%BB%A7%E6%99%B7/%E6%8A%80%E6%9C%AF%E7%AE%A1%E7%90%86/"/>
    
    
      <category term="Technique" scheme="http://luxialan.com/tags/Technique/"/>
    
  </entry>
  
</feed>
